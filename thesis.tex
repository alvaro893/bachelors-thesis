%----------------------------------------------------------------------------------------
%	TITLE PAGE CONFIGURATION
%----------------------------------------------------------------------------------------

\def\thesislang{english} %change this depending on your language
\author{Álvaro Bolaños Rodríguez}
\def\thesis{Bachelor's Thesis}
\def\alaotsikko{}

%Finnish section
\def\otsikko{Opinnäytetyön otsikko}
\def\tutkinto{Tutkinto}
\def\kohjelma{Koulutusohjelma}
\def\suuntautumis{Suuntautumisvaihtoehto}
\def\ohjaajat{
Etunimi Sukunimi, Titteli\newline
Etunimi Sukunimi, Titteli
}
\def\avainsanat{avainsanat}
\def\pvm{\specialdate\today}

%English section, for abstract
\title{Cloud Communication Channel for Thermal Cameras}
\def\metropoliadegree {Bachelor of Engineering}
\def\metropoliadegreeprogramme {Information Technology}
\def\metropoliaspecialisation {Software Engineer}
\def\metropoliainstructors {
Dr. Tero Nurminen, Principal Lecturer \newline
}
\def\metropoliakeywords {IoT, IR, sensor, cloud, full-stack, communication channel, websocket, http, LTE, Android, Python}
\date{\today}

%----------------------------------------------------------------------------------------
%	GLOBAL STYLES
%----------------------------------------------------------------------------------------

\documentclass[hidelinks,11pt,a4paper,oneside,article]{memoir}
\usepackage[\thesislang]{babel} 
\usepackage{iflang}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{fontspec}
\usepackage{tocloft}
\usepackage{titlesec}
\usepackage[hyphens]{url}
\usepackage{mathtools}
\usepackage{wallpaper}
\usepackage{datetime}
\usepackage[bookmarksdepth=subsection]{hyperref} % for automagic pdf links for toc, refs, etc.
\usepackage[amssymb]{SIunits}
\usepackage[version=3]{mhchem}
\usepackage{pgfplots} %simple plots etc
\usepackage{pgfplotstable}
\usepackage{tikz} % mindmaps, flowcharts, piecharts, examples at http://www.texample.net/tikz/examples/
\usepackage{csquotes}
\usepackage{xparse}
\usepackage{tabu}
\usetikzlibrary{shapes.geometric, arrows}
%\numberwithin{equation}{chapter} % this add the chapter in the equation



\renewcommand{\dateseparator}{.}
%condition for adding or not space in TOC
\usepackage{etoolbox}
%for compact list
\usepackage{enumitem}
%for block comment
\usepackage{verbatim}
%for "easier" references
\usepackage{varioref}
%forcing single line spacing in bibliography
\DisemulatePackage{setspace}
\usepackage{setspace}
%including figure (image)
\usepackage{graphicx}
%change the numbering for figure
\usepackage{chngcntr}
%strike trough
\usepackage{ulem}
%euro symbol
\usepackage{eurosym}
%try to count
\usepackage{totcount}
%insert source code
\usepackage{listings}
\usepackage[justification=centering,singlelinecheck=false]{caption}
\usepackage{color}
%force the width of a table instead of column
\usepackage{tabularx}
\usepackage{booktabs} %why not booktabs? :3
% Abbreviations, acronym and glossary
\usepackage[acronym,nonumberlist,section]{glossaries}%xindy,%toc, ,nomain

\usepackage{float} % For forced figure location with modifier H (\begin{figure}[H])
\usepackage{cite} % Make citations to match Metropolia thesis guide

% change font of links in bibliography to same as other text
\usepackage{url}
\urlstyle{same}

% change punctuation of multiple cites to semicolon instead of comma: [1; 2; 3]
\renewcommand\citepunct{; }

% citep-macro for reference with period inside square brackets [1.]
\newcommand{\citep}[1]{
 \renewcommand\citeright{.]}
 \cite{#1}
 \renewcommand\citeright{]}
}

%set date format to D.M.YYYY
\newdateformat{specialdate}{\THEDAY.\THEMONTH.\THEYEAR}

\newcommand\tn[1]{\textnormal{#1}} %use \tn instead of \textnormal
\newcommand\reaction[1]{\begin{equation}\ce{#1}\end{equation}} %\reaction{} for chemical reactions

%----------------------------------------------
% CUSTOM COMMANDS
%----------------------------------------------
\newcommand{\putimage}[3][10] %[3]: 3 parameters, [10] default value for 1st parameter is 10
{
\begin{figure}[h]
	\centering
	\captionsetup{justification=centering}
	\includegraphics[width=#1cm]{#2}
	\caption{#3}
	\label{fig:#2}
\end{figure}
}
% idea for this command from http://tex.stackexchange.com/questions/25597/wrapping-code-listings-verbatim-or-other-method-inside-a-newcommand
\ExplSyntaxOn
\NewDocumentCommand{\putcode}{m m O{} +v }
{
	\begin{figure}[h]
%		\centering
%		\captionsetup{justification=centering}
		 \newlinechar=\endlinechar
		 \exp_args:Nx \scantokens
		 {
		 	\string\begin{lstlisting}[caption={#2},label={listing:#1},\unexpanded{#3}]
		 	#4
		 	\string\end{lstlisting}
		 }

%		\caption{#2}
%		\label{fig:#1}
	\end{figure}\vspace{-17pt}
}
\ExplSyntaxOff

%PROGRAMMING LANGUAGE DEFINITIONS
\lstdefinelanguage{JavaScript}{
    keywords={typeof, new, true, false, catch, function, return, null, catch, switch, const, var, if, in, while, do, else, case, break},
    keywordstyle=\color{blue}\bfseries,
    ndkeywords={class, export, boolean, throw, implements, import, this},
    ndkeywordstyle=\color{darkgray}\bfseries,
    identifierstyle=\color{black},
    sensitive=false,
    comment=[l]{//},
    morecomment=[s]{/*}{*/},
    commentstyle=\color{purple}\ttfamily,
    stringstyle=\color{red}\ttfamily,
    morestring=[b]',
    morestring=[b]"
}
%NORMAL TEXT
%all text, title, etc. in the same font: Arial
%replace with arial.ttf if you have the fontfile
\setmainfont
[BoldFont=LiberationSans-Bold.ttf,
ItalicFont=LiberationSans-Italic.ttf,
BoldItalicFont=LiberationSans-BoldItalic.ttf]
{LiberationSans-Regular.ttf}
%line space
\linespread{1.5}
%\doublespacing
%margin
\usepackage[top=2.5cm, bottom=3cm, left=4cm, right=2cm, nofoot]{geometry}
\setlength{\parindent}{0pt} %first line of paragraph not indented
\setlength{\parskip}{16.5pt} %one empty line to separate paragraph
%list with small line space separation
\tightlists

%IMAGE - FIGURE
%the figures should be placed in the "illustration" folder
\graphicspath{{illustration/}}
%figure number without chapter (1.1, 1.2, 2.1) to (1, 2, 3)
\counterwithout{figure}{chapter}
%border around images
\setlength\fboxsep{0pt}
\setlength\fboxrule{0.5pt}
%caption font size
\captionnamefont{\small}
\captiontitlefont{\small}
%space after figure caption (and other float elements)
\setlength{\belowcaptionskip}{-7pt}

%TABLE
\counterwithout{table}{chapter}

%SOURCE CODE
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}
\lstset{
extendedchars=true,
captionpos=b,
caption=\footnotesize,
basicstyle=\singlespacing\ttfamily,%\small\fontfamily{"Courier"}\selectfont,
keywordstyle=\color{blue}\bfseries,
commentstyle=\color{purple}\itshape,
identifierstyle=\color{black},
stringstyle=\color{red},
showstringspaces=false,
showspaces=false,
numbers=left,
numberstyle=\footnotesize,
numbersep=9pt,
breaklines=true,
tabsize=2,
showtabs=false,
xleftmargin=1cm
}
\IfLanguageName {finnish} {\renewcommand{\lstlistingname}{Listaus}} {} % what is a good translation for this?
%\counterwithout{lstlisting}{chapter}
%moved after begin document, otherwise does not compile

%% set this format as the default for lstlisting
%\DeclareCaptionFormat{empty}{}
%\captionsetup[lstlisting]{format=empty}

%TOC
%change toc title
\IfLanguageName {finnish} {\addto{\captionsfinnish}{\renewcommand*{\contentsname}{Sisällys}}} {}
%remove dots
\renewcommand*{\cftdotsep}{\cftnodots}
%chapter title and page number not in bold
\renewcommand{\cftchapterfont}{}
\renewcommand{\cftchapterpagefont}{}
%sub section in toc
\setcounter{tocdepth}{2}
%subsection numbered
\setcounter{secnumdepth}{2}
\renewcommand{\tocheadstart}{\vspace*{-15pt}}
\renewcommand{\printtoctitle}[1]{\fontsize{13pt}{13pt}\bfseries #1}
\renewcommand{\aftertoctitle}{\vspace*{-22pt}\afterchaptertitle}
%spacing afer a chapter in toc
\preto\section{%
  \ifnum\value{section}=0\addtocontents{toc}{\vskip9pt}\fi  % original was \vskip11pt
}
%spacing afer a section in toc
\renewcommand{\cftsectionaftersnumb}{\vspace*{-3pt}}
%spacing afer a subsection in toc
\renewcommand{\cftsubsectionaftersnumb}{\vspace*{-1pt}}
%appendix in toc with "Appendix " + num
\IfLanguageName {finnish} {
  \renewcommand*{\cftappendixname}{Liite\space}
  \renewcommand{\appendixtocname}{Liitteet}
}{\renewcommand*{\cftappendixname}{Appendix\space}}
%appendix header
\IfLanguageName {finnish} {\def\appname{Liite\space}}{\def\appname{Appendix\space}}

%TITLES
%chapter title
\titleformat{\chapter}
{\fontsize{13pt}{13pt}\bfseries\linespread{1}}
{\thechapter}{.5cm}{}
\titlespacing*{\chapter}{0pt}{.32cm}{9pt}
\titleformat{\section}
{\fontsize{12pt}{12pt}\linespread{1}}
{\thesection}{.5cm}{}
\titlespacing*{\section}{0pt}{14pt}{6pt}
\titleformat{\subsection}
{\fontsize{12pt}{12pt}\linespread{1}}
{\thesubsection}{.5cm}{}
\titlespacing*{\subsection}{0pt}{14pt}{6pt}


%QUOTE
\renewenvironment{quote}
  {\list{}{\rightmargin=0pt\leftmargin=1cm\topsep=-10pt}%
  \item\relax\fontsize{10pt}{10pt}\singlespacing}
  {\endlist}

%BIBLIOGRAPHY
%bibliography title to be "references"
%if the title don't get renamed properly, move that line after the \begin{document}
\IfLanguageName {finnish} {\addto{\captionsfinnish}{\renewcommand*{\bibname}{Lähteet}}} {\renewcommand\bibname{References}}
\makeatletter %reference list option change
\renewcommand\@biblabel[1]{#1\hspace{1cm}} %from [1] to 1 with 1cm gap
\makeatother %
\setlength{\bibitemsep}{11pt}

%count the appendices (since the chapter counter is reset after \appendix).
%! require to complie 2 times
\regtotcounter{chapter}

%ABBREVIATION AND GLOSSARY
% Generate the glossary
\makeglossaries

%Acronyms, abbreviations, etc. definitions
\newacronym{html}{HTML}{HyperText Markup Language}
\newacronym{sql}{SQL}{Structured Query Language}
\newacronym{io}{I/O}{Input/Output}
\newacronym{ram}{RAM}{Random Access Memory}
\newacronym{php}{PHP}{Hypertext Preprocessor}
\newacronym{lte}{LTE}{Long Term Evolution}
\newacronym{3g}{3G}{Third Generation Mobile Network}
\newacronym{ir}{IR}{Infrared}
\newacronym{iot}{IoT}{Internet of Things}
\newacronym{usb}{USB}{Universal Serial Bus}
\newacronym{sim}{SIM}{subscriber identity module}
\newacronym{spi}{SPI}{Serial Peripheral Interface}
\newacronym{api}{API}{Application Program Interface}
\newacronym{otg}{OTG}{USB On-The-Go}
\newacronym{ui}{UI}{User Interface}
\newacronym{http}{HTTP}{Hypertext Transfer Protocol}
\newacronym{https}{HTTPS}{HTTP over SSL}
\newacronym{tcp}{TCP}{Transmission Control Protocol}
\newacronym{udp}{UDP}{User Datagram Protocol}
\newacronym{rtp}{RTP}{Real Time Transport Protocol}
\newacronym{uml}{UML}{Unified Modeling Language}
\newacronym{er}{ER Diagram}{Entity Relationship Diagram}
\newacronym{paas}{PaaS}{Platform As A Service}
\newacronym{saas}{SaaS}{Software As A Service}
\newacronym{iaas}{IaaS}{Infrastructure As A Service}
\newacronym{cpu}{CPU}{Central Process Unit}
\newacronym{ssh}{SSH}{Secure Shell}
\newacronym{oop}{OOP}{Object Oriented Programming}
\newacronym{cpp}{C++}{C plus plus}
\newacronym{xml}{XML}{Extensible Markup Language}
\newacronym{json}{JSON}{JavaScript Object Notation}
\newacronym{uri}{URI}{Uniform Resource Identifier}
\newacronym{npm}{NPM}{Node Packet Manager}
\newacronym{ip}{IP}{Internet Protocol}
\newacronym{ran}{RAN}{Radio Access Network}
\newacronym{s2i}{S2I}{Source-to-Image}
\newacronym{cvs}{CVS}{Control Version System}
\newacronym{voip}{VoIp}{Voice over IP}
\newacronym{nat}{NAT}{Network Address Translation}
\newacronym{vpn}{VPN}{Virtual Private Network}
\newacronym{www}{WWW}{World Wide Web}
\newacronym{pdf}{PDF}{Portable Document Format}
\newacronym{ascii}{ASCII}{American Standard Code for Information Interchange}




%Glossary entries
\newacronym{ws}{Websocket}{Application protocol build on top of TCP}

\newacronym{github}{GitHub}{Hosting site for Git repositories}

\newacronym{git}{Git} {Control version software}

\newacronym{docker}{Docker}{Software container platform}

\newacronym{kubernetes}{Kubernetes}{Automated container deployment, scaling, and management}

\newacronym{apache}{Apache} {the most used web server software in the world}

\newacronym{android}{Android} {Operative System used mainly in smartphones}

\newacronym{matplotlib}{Matplotlib} {Plotting library for Python programming language}

\newacronym{qt}{Qt}{Cross-platform application framework}

\newacronym{labview}{LabVIEW} {environment for visual programming language used for instrument control}


\newacronym{tcpip}
{TCP/IP}{All the necessary layers to match the conceptual model of the Internet protocol suite}

\newacronym{rs232}
{RS-232}{A standard for serial communications}

\newacronym{java}
{Java}{Programming language able to run on most of the Operative Systems}

\newacronym{javame}
{Java ME}{Java Micro Edition: Java version for mobile or embedded devices}

\newacronym{midlet}
{MIDlet}{ A MIDlet is an application that uses the Mobile Information Device Profile (MIDP) on Java ME environment}
\newacronym{js}
{Javascript}{Dynamic programming language used mostly in browsers although can be used in desktop and server applications}
\newacronym{nodejs}{Node.js}
    {Node.js is an open-source, cross-platform JavaScript runtime environment for developing server-side applications}
\newacronym{python}
{Python}
    {Dynamic typed interpreted programming language}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------
\makeatletter
\renewcommand{\maketitle}{
\thispagestyle{empty}
\ThisCenterWallPaper{1}{viiva}
%
\vspace*{9.5cm}
\tn{\LARGE\@author\\[22pt]\Huge\IfLanguageName {finnish}{\otsikko}{\@title}\\[22pt]\LARGE\alaotsikko\\[1.75cm]}

\parbox{.7\linewidth}{
\IfLanguageName {finnish}{
  Metropolia Ammattikorkeakoulu\\
  \tutkinto \\
  \kohjelma \\
  \thesis\\
  \pvm
} {
  Helsinki Metropolia University of Applied Sciences\\
  \metropoliadegree \\
  \metropoliadegreeprogramme \\
  \thesis\\
  \specialdate\today % D.M.YYYY date format
}
}
\ThisLRCornerWallPaper{1}{metropolia}
%
\clearpage
}
\makeatother

\makepagestyle{tiivis}
\makeevenhead{tiivis}{}{}{Tiivistelmä}
\makeoddhead{tiivis}{}{}{Tiivistelmä}

\makepagestyle{abstract}
\makeevenhead{abstract}{}{}{Abstract}
\makeoddhead{abstract}{}{}{Abstract}

% BEGIN OF DOCUMENT
\begin{document}
\renewcommand\bibname{References}
\counterwithout{lstlisting}{chapter}
\lstdefinestyle{styleprogramming}{
	basicstyle=\ttfamily\small\captionsetup{justification=centering},
	commentstyle=\ttfamily\color{violet}
}
\lstdefinestyle{styleprogrammingappendix}{
    basicstyle=\ttfamily\scriptsize\captionsetup{justification=centering},
    commentstyle=\ttfamily\color{violet}
}
%\lstdefinestyle{styleprogrammingcomments}{commmentstyle=\ttfamily\color{violet}}
%\lstdefinestyle{styleprogramming}{basicstyle=\ttfamily\small,numbers=none}

%page number always on the top right, clear the "chapter/section" head
\pagestyle{myheadings}
\markright{}
%clear chapter "title" foot page
\makeevenfoot{plain}{}{}{}
\makeoddfoot{plain}{}{}{}



\maketitle
\newpage

\LRCornerWallPaper{1}{footer}

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\pagestyle{abstract}
\begin{tabular}{ | p{4,7cm} | p{10,3cm} |}
  \hline
  Author(s) \newline
  Title \newline\newline 
  Number of Pages \newline
  Date
  & 
  \makeatletter
  \@author \newline
  \@title \newline\newline
  \pageref*{LastPage} pages + \total{chapter} appendices \newline %! if no appendices, risk to count total of chapter :D
  \IfLanguageName {finnish} {\foreignlanguage{english}{\longdate\@date}} {\@date}
  \makeatother
  \\ \hline
  Degree & \metropoliadegree
  \\ \hline
  Degree Programme & \metropoliadegreeprogramme
  \\ \hline
  Specialization option & \metropoliaspecialisation
  \\ \hline
  Instructor(s) & \metropoliainstructors
  \\ \hline
  \multicolumn{2}{|p{15cm}|}{\begin{singlespacing}\vspace{-22pt}

 The objective of this thesis was to develop an effective bidirectional communication system for thermal sensors from the company LeViteZer using an IoT approach and connecting them through cloud services and mobile networks provided by the Nokia Innovation Platform.\newline
\newline
 On the thesis there is described different methods to build this communication channel from a full stack point of view. In this case there are a sensor-side, a client-side and a server-side methods.\newline
\newline
 The outcome of this project was an set of pieces of applications to make the communication system using technologies and frameworks available to any software developer. This communication system as the date of the publication of this thesis was tested and met the expectations set on business challenge on the Introduction chapter and it is likely to be continued its development.\newline
  \newline
 It is discussed possible applications of this system in the context of the Nokia Innovation Platform, Well-being services and some other cases.

  \end{singlespacing}} \\[14cm] \hline
  Keywords & \metropoliakeywords
  \\ \hline
\end{tabular}
\clearpage

%----------------------------------------------------------------------------------------
%	Acknowledgement ?
%----------------------------------------------------------------------------------------
%\chapter*{Acknowledgement}
%Thanks to my cat
%\clearpage

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

\makeevenhead{plain}{}{}{}
\makeoddhead{plain}{}{}{}
\pagestyle{empty} %remove page number in toc (if longer than 2 pages)
\tableofcontents*
\pagestyle{empty} %remove page number in toc (if longer than 1 pages)


\clearpage
%Uncomment this line if you do not have Abbreviations list.
%\pagestyle{plain}

%list of figure, tables comes here...
%\listoffigures
% Sotavalta:Do not include a separate list of tables and/or figures in your thesis.

%----------------------------------------------------------------------------------------
%    Lyhenteet / Abbreviation
%----------------------------------------------------------------------------------------

\begin{singlespacing}

\glsaddall

{
	\titleformat{\section}
	{\fontsize{13pt}{13pt}\bfseries\linespread{1}}
	{\thesection}{.5cm}{}
	%Adapt labelwidth (sorry for the ugly hack)
	\setlist[description]{leftmargin=!, labelwidth=4em}
	\IfLanguageName {finnish} {
		\printacronyms[title=Lyhenteet]
	}{
		\printacronyms[title=Abbreviations and Terms]
	}
	\setlist[description]{leftmargin=!, labelwidth=7em}
	%\printglossary[title=]
	\setlist[description]{style=standard} % reset settings back to default
}
\end{singlespacing}
%Seems that bug is in sharelatex. Compile fine with TexLive >= 2014


\newpage

%page number always on top right; also for chapter "title" page
\pagestyle{plain}
\makeevenhead{plain}{}{}{\thepage}
\makeoddhead{plain}{}{}{\thepage}

\setcounter{page}{1} %page 1 should be Introduction
\ClearWallPaper
%----------------------------------------------------------------------------------------
%	CONTENT
%----------------------------------------------------------------------------------------

\sloppy % enforce alignment to fully justified

\chapter{Introduction}\label{sec:introduction}


Thermal images have a number of advantages over conventional light-based video camera images.   These thermal images can tell not only whether there are living people or animals but also whether there is any temperature anomaly on them. They can be used to make assumptions about their physical state or understand how a group of individuals move or behave using Computer Vision software.

Keeping into account that Nordic European countries and specially Finland are rapidly aging, costs in elder and general health care are becoming more expensive. Health care entities may decrease their costs by search for new ideas in the field of IT. In the discussion chapter some ideas to use thermal or \gls{ir} sensors and the communication channel are explained~\cite{agingeuropa}.

Here is where \gls{iot} comes into play, Nowadays the Internet is very accessible and fast. Almost every conceivable device: phones, watches, televisions, speakers, cameras, etc can be connected, send and receive continuously big amounts of data.

Although with \gls{iot} it comes the process of defining a communication channel between the \gls{iot} devices, services, clients, databases, etc. In order to manipulate, visualize, store and distribute data from them. On this thesis it is explained the steps that were followed to develop the solutions to these topics and what alternatives were tried and what tools/technologies were used to carry out the project.


\section*{Background of the case company}
The thesis originates in a collaboration with the case company called LeViteZer (\url{http://www.levitezer.com/}), Metropolia and Nokia.
 LeViteZer is company that develops controllers for cameras for image stabilization such as gimbals~\cite{levitezer}. They provide the \gls{ir} sensors. Nokia with their innovation platform~\cite{nokiainnovation}, provides the cloud environment and the network. My part as Metropolia student is develop the mentioned communication channel.



\section*{Business Challenge}\label{sec:business-challenge}
%% improving costs by not having personal watching people all the time
The case company wants to find a system which uses \gls{ir} sensors that allow us to monitor patients while keeping their privacy along with reducing costs by using less staff and improve the service quality. Moreover, it should be possible to access data from those sensors fro anywhere which make them very versatile and portable.

\section*{Objective and Outcome of the Study}
With the business challenge in mind, this study aims to answer the following question:
\begin{displayquote}
{\large  How to create an effective communication channel between \gls{ir} sensors and clients such as computers, laptops, etc and use it on Well-being services?}
\end{displayquote}

The outcome of this study is:
\begin{enumerate}
\item Different client-side applications able to connect to sensors.
\item An web \gls{api} that connect \gls{ir} sensors to a cloud hence to clients.
\item Proposals to use the resulting communication system on health care institutions.
\end{enumerate}



\clearpage\chapter{Theoretical Background}\label{sec:theoretical-background}
%What is already known about your chosen subject area and what is not known?
%Discuss ideas in previous studies relevant to your topic (a brief introduction to the current state of knowledge and practice in your subject area). Identify a gap in the subject area and justify the purpose of your project, that is, the focus of your topic.

Communications between devices is not a new topic, there are plenty of methods and communications protocols, this can be also part of the problem: there are too many of them and sometimes this can be overwhelming. In this section it is described what is known about communication and network protocols in order to find the best way to create a communication channel as stated in the business challenge on section~\ref{sec:business-challenge} of the introduction.



\section{Communication Between Devices}
% Talk about what is know about communication systems, full stack development, etc
In order to establish a communication between two ends in a computer network or in Internet it is good to comprehend how the "Internet Protocol Architecture" or \gls{tcpip} stack works. Most of networks are based on it, including office and home networks~\cite[9]{tcpip}.

	\putimage[5]{tcpip}{\gls{tcp}/\gls{ip} Architecture}

The \gls{tcp}/\gls{ip} stack is build in layers:
\begin{enumerate}
	\item Network Access Layer: physical medium to access the network.
	\item Internet Layer: handles the routing of data
	\item Transport Layer: provides host to host data delivery services.
	\item Application Layer: applications and process that make use of the network
\end{enumerate}

Then, a way to communicate through the \gls{tcp}/\gls{ip} stack as shown in figure~\ref{fig:tcpip} must be found.

\section{The Medium}\label{sec:the-medium}
At this point it has to be decided what physical medium to \textit{access the network} (Network Access Layer in figure~\ref{fig:tcpip}). It could be a simple copper cable, Wi-Fi, microwaves, laser, etc. almost any kind of electromagnetic wave. But since this is an \gls{iot} project the best approach will be using \gls{ran} which it is accessible from cell antennas and nowadays provide great speeds and bandwidth.

As stated in the Introduction, Nokia provides access to a mobile network. This network is called NetLeap which uses \gls{3g} and \gls{lte} technologies (the same that use mobile phones to connect to Internet). NetLeap is a closed network for research managed by Aalto University and Nokia~\cite{netleap}.

\section{Network Protocols}
The Internet Layer protocols usually rely in routers and other apparatus which are out of our control, hence the only concern is about transport and application layer.

The idea is to use reliable application protocol to make the connections and this should be platform independent and a Internet standard, these protocol standards specifications are available officially in \url{https://www.rfc-editor.org/standards}. On the next sections are the protocols considered and the reasoning behind them.


\subsection{UDP}
\Gls{udp} is a connectionless transport protocol, it does not guaranty delivery nor order of packets which means they can get lost and will not be re-requested and might come in a different order than when they were sent~\cite[18]{tcpip}.

\gls{udp} is commonly used to provide real communication such as time video stream on protocols as \gls{rtp}, it is also used in \gls{voip} to deliver telephone calls over network. They take advantage about the connectionless nature of \gls{udp} which despite  the mentioned disadvantages it has a low latency. On the other hand losing some packets during a call or video retransmission is not a big deal. 

Then a \gls{udp} communication system may be suitable for this project since, what it is sending from the \gls{ir} sensors is a binary stream of images. Commands can be sent over \gls{udp} as well.
This can be done sending packets between sensors and clients directly or through a server which could coordinate the data flow.

\subsubsection{Port Issues on Remote Hosts}\label{sec:port-issues-on-remote-hosts}
Routers and firewalls usually do not accept connection from ports other than 80 and 443. This is an issue when using \gls{udp} (or \gls{tcp}) sockets approaches. In a local network usually there are no such issues (although firewalls could be strict, depends upon the local network administrators), so a solution can be using a \gls{vpn} provider which allows remote computers act as if they where in a local network and increase the security as well.

Another solution is \gls{udp} hole punching technique to establish bidirectional communication between hosts that are behind \gls{nat} routers by using a external host to keep track of the ports and addresses used in the \gls{nat} tables of both hosts routers.




\subsection{TCP}
\gls{tcp} is the other transport layer protocol, unlike \gls{udp}, \gls{tcp} is connection based and guaranties the delivery and order of packets. Thus protocols made on top of \gls{tcp} establish a connection and have to maintain it, which increases the latency~\cite[19]{tcpip}.

\subsubsection{Http}\label{sec:http}
\gls{http} and \gls{https} is application layer protocol made on top of \gls{tcp}. \gls{http} is meant to request resources such as \gls{html} documents, \gls{xml}, \gls{json} or plain text. Any request has a response which can contain a body of data and response code (like the famous "404 not found")~\cite{http-rfc}.

\gls{http} is strongly related to the \gls{www}, on most of routers and firewalls the port 80 (\gls{http}) and 443 (\gls{https}) are allowed. In addiction, the \gls{http} responses can be used to receive data from the other end indirectly. This could be used for a request-response sensor-client communication approach using a third party like a server.

\putimage[14]{http-approach}{Http/s approach}

As seen in figure~\ref{fig:http-approach} both sensor and client use requests to send data (which is between "<>" signs in the figure) that other end expect to receive in the response. A server application take cares to forward requests data to responses. Thus all requests are always towards the server and must be continuous.

\subsubsection{Websocket}
\gls{ws} is a relatively new protocol (end of 2011) which was meant to provide web applications with bidirectional communication without making continuous \gls{http} requests through techniques like XMLHttpRequest~\cite[4]{rfc6455}.

As \gls{http}, \gls{ws} use ports 80 and 443 (secure \gls{ws}) by default then it can go through \gls{nat} and firewalls easily. Once a connection is established both ends can receive and send data until the connection is closed. This connection is started with a handshake in form of a \gls{http} GET request~\cite[6]{rfc6455}. 



\clearpage\chapter{Methods and Materials}\label{sec:methods-and-materials}
%How was the project carried out in practice, and how was the data analysed?
%Describe the context in which the work was carried out (such as the overall project and its design, your specific task, work environment) and the workflow. Describe the methods and materials used (accurate details of data, software, materials, methods, techniques). Give a full account of exact test arrangements and measurements carried out, and accurate details of data analysis.
%The issues included in this section depend on the nature of your project. Whatever the issues, describe them in sufficient detail and in logical sequence.

The aim of this project is to design methods to transmit data from one sensor to a client application and vice-versa. Also define a generalization to communicate from $N$ sensors to $M$ client applications, being either $N$ and $M$ arbitrary numbers. Note that the communication must be bidirectional since clients can send commands to sensors in order to perform operations such as calibration, delay between frames, etc. On this communication system there are 3 well differentiated parts:
\begin{itemize}
    \item Sensor side: software that connects the sensor with the server side.
    \item Server side: software that connects sensors and clients together.
    \item client side: software that connects the an user with the server side to access a sensor.
\end{itemize}

The figure~\ref{fig:communication-channel} shows this idea.

\putimage{communication-channel}{A communication channel}

This chapter discuss about methods for each side of the communication system in detail.


\section{The Sensor}
The \gls{ir} sensor provided by LeViteZer delivers all infrared data in form of binary streams trough \gls{usb}.

 In order to make the an image it is necessary to process those streams. Every image or frame comes in 240 rows of 80 bytes of data separated by a delimiter of 3 bytes plus an extra byte that identify the row:

\begin{equation}
\label{eq:sensor-stream}
\text {FF FF FF 00} \left\lbrace data \right\rbrace 
\text {FF FF FF 01} \left\lbrace data \right\rbrace 
\text {FF FF FF 02} \left\lbrace data \right\rbrace \dots
\end{equation}



In equation~\ref{eq:sensor-stream} every byte is on hexadecimal format containing a sequence "FF FF FF" which is at the beginning of every row. After this sequence, the 4th byte is the number which identify the row from 0 to 240.

As equation~\ref{eq:metadata-row} shows, The 240th (F0 in hexadecimal) and last row provides meta-data about the frame

\begin{equation}
\label{eq:metadata-row}
\dots \text {FF FF FF F0} \left\lbrace metadata \right\rbrace
\end{equation}
In table~\ref{table:metadata-row} are listed all information contained in the meta-data.

\subsubsection{Meta-Data}
Every frame comes with valuable data about its state and sensor's such as configuration, temperature parameters, etc.
\begin{table}[h]
    \centering
    \begin{tabu}{| l | c |}
        \hline
        \rowfont[c]{\bfseries} Meta-Data Parameter & Bytes (from 0 to 80) \\ \hline

        Time counter & 4,3,1,0 \\
        Frame counter & 10,9,7,6 \\
        Frame Mean & 13,12 \\
        Sensor temperature & 16,15 \\
        Maximum temperature & 19,18 \\
        Minimum temperature & 22,21 \\
        Discarded packets count & 25,24 \\
        Maximum temperature limit & 28,27 \\
        Minimum temperature limit & 31,30 \\
        AGC byte & 34 \\
        Bit depth & 35 \\
        Delay between frames & 37,36 \\
        \hline
    \end{tabu}
    \caption{Meta-data and its position in the row}
    \label{table:metadata-row}
\end{table}

Here is a short explanation about the meta-data values:
\begin{itemize}
    \item Time counter: Amount of seconds since the sensor was power on.
    \item Frame counter: Amount of frames since the sensor was power on.
    \item Frame mean: Temperature mean of the frame.
    \item Sensor temperature: temperature of the sensor itself.
    \item Maximum temperature: maximum temperature registered the current frame.
    \item Minimum temperature: minimum temperature registered the current frame.
    \item Discarded packets: packets that were not read. a great number may tell that the application is not reading the sensor fast enough.
    \item Maximum temperature limit: The limit set with the command for maximum limit.
    \item Minimum temperature limit: same that previous but with minimum temperature.
    \item AGC byte: tell if the limits are set or not (useful for implementing indicators).
    \item Bit depth: bit depth of the image, it can be 0, 2 or 8 (default).
    \item Delay between frames: if no delay is set (delay=0) then the delay is about 111 milliseconds (9 frames per second).
\end{itemize}
Note: Temperatures from sensors are not in absolute values, this is because the sensor does not detect particular values but difference in temperature.

\subsubsection{Commands} \label{commands}
% TODO: more Pictures of the sensors
The commands are sent over the same serial \gls{usb} cable from which the frames are received. In table~\ref{table:commands} the main commands are displayed along its binary representation: for the first byte an \gls{ascii} character and for the data argument it depends upon the command.

\begin{table}[h]
    \centering
    \begin{tabu}{| l | c | c |}
        \hline
        \rowfont[c]{\bfseries} Command Name & Command (\gls{ascii} byte) & Arguments \\ \hline
        
       Synchronize 		                    & S & No      \\
       Calibrate   		                    & C & No      \\
       Set Maximum Temperature Limit        & H & 2 bytes \\
       Set Minimum Temperature Limit        & L & 2 bytes \\
       Auto Maximum Temperature Limit       & A & No	  \\
       Auto Minimum Temperature Limit       & a & No	  \\
       Set Bit Depth                        & B & 1 byte  \\
       Set Frame Delay                      & U & 2 bytes \\

        \hline
    \end{tabu}
    \caption{Commands accepted by the sensor}
    \label{table:commands}
\end{table}

Note: The frame-rate is 9 frames per second at maximum, although the sensor can be configured with an arbitrary delay time between frames.

\subsubsection{Creating the Image}\label{creatingimage}
Every frame has a size of 160x120 pixels, but the image data comes in a matrix of 80x239 (240 is the meta-data row) as equation~\ref{eq:sensor-stream} and \ref{eq:metadata-row} shown before. Each byte of data can be seen as a pixel in a gray-scale image, but in order to generate the correct image the "data matrix" must be reshaped to 160x120 as show in the figure~\ref{fig:sensor-image}. Every 2 row in the data matrix make 1 row in the image.
\putimage{sensor-image}{Reshaping data}

In the future the number of pixels might change so it is better to define a generalized solution to do the reshaping:

For each data row (equation~\ref{eq:data}) let $n_j$ be the data current row number performing by the 4th byte in equation~\ref{eq:sensor-stream}, then for every $d_i$ value in the data row is possible to define every pixel $p_{ij}$ of the image matrix (equation~\ref{eq:image}) as a coordinate pair $(x,y)$ in the data matrix. $s$ is the size of the data row which is 80 in this case.
\begin{equation}
\label{eq:data}
D_{i,j} = 
\begin{pmatrix}
    n_1 & d_{1,1} & d_{1,2} & \cdots & d_{i,1}\\
    n_2 & d_{2,1} & d_{2,2} & \cdots & d_{i,2}\\
 \vdots & \vdots  & \vdots  & \ddots & \vdots  \\
    n_j & d_{1,j} & d_{2,j} & \cdots & d_{i,j}\\
\end{pmatrix}
\end{equation}

\begin{equation}
\label{eq:image}
I_{i,j} = 
\begin{pmatrix}
    p_{1,1} & p_{1,2} & \cdots & p_{1,j} \\
    p_{2,1} & p_{2,2} & \cdots & p_{2,j} \\
    \vdots  & \vdots  & \ddots & \vdots  \\
    p_{i,1} & p_{i,2} & \cdots & p_{i,j} 
\end{pmatrix}
\end{equation}

\begin{equation}
\label{eq:coordinate}
x = n_j \backslash 2  \qquad y = n_j \bmod s + i
\end{equation}

\begin{equation}
\label{eq:pixel}
p_{ij} = d_{xy}
\end{equation}

As seen in equation~\ref{eq:pixel} any pixel value corresponds to a x,y pair define in equation~\ref{eq:coordinate} .

Note the "\textbackslash" here is meant for integer division in equation~\ref{eq:coordinate}, it is \textbf{not} a normal division with rational or decimal numbers. "mod" function represents the modulus operation which finds the remainder of a division.

As an example of a practical implementation in \gls{python} see the listing~\ref{listing:image-python} which function process{\_}data{\_}row is called for every data row

\putcode{image-python}{Simplified example of creating a frame in Python}[language=Python,style=styleprogramming]$
self.frame_arr[f_row][f_col]

def process_data_row(self, row):
    n_row = row[0]
    
    for indx, val in enumerate(row[1:]):
        f_row = (n_row)/2
        f_col = (n_row) % 2 * 80 + indx
        self.frame_arr[f_row][f_col] = val
$ 

Also note that in order to fill the "self.frame{\_}arr" matrix the function is must be called 239 times

\section{Sensor Side Methods}
The sensor has been described in the previous section. Here different methods to read the sensor are discussed, some worked better than others, nevertheless all of what was tried is included.

\subsection{Android Smartphone as Gateway}
Most of Android smartphones have an \gls{otg} which allows to use \gls{usb} peripherals in the phone with the correspondent \gls{otg} adapter This can be used to develop an Android application to receive the data from the sensor and send it through Internet using any protocol, in this sense the cellphone act as a gateway to Internet, letting the sensor access the \gls{3g} or the \gls{lte} network.

An advantage of this approach is that the smartphone(including a \gls{sim} card) has all the hardware on it to make the communication. Hence there is only need to focus on the software part.

This was tested using a \gls{php} file in a server on Metropolia UAS alongside an Android Application I developed to send all the data from the sensor to server.

Note that this method requires  a terminal which supports \gls{usb} \gls{otg}.

\subsubsection{Description of the Android Application}
To create the Android application it is needed some things:
\begin{itemize}
	\item A minimal \gls{ui}
	\item A network protocol and its implementation
	\item A background process
\end{itemize}

The \gls{ui} let us start the reading and provide an address and a port to connect. See figure~\ref{fig:android-screenshot}.
\putimage[5]{android-screenshot}{\gls{ui} of the Android Application}


As network protocol \gls{http} was chosen, although it is not the best for continuously sending data. Then an \gls{php} script processed the request and store the data in form of hexadecimal strings in a file as listing~\ref{listing:php-script} illustrates

% more options for code https://www.sharelatex.com/learn/Code_listing#/Options_to_customize_code_listing_styles
\putcode{php-script}{PHP code in the server side}[language=PHP,style=styleprogramming]^
<?php
$data = "";
// get data only from post request
if ($_SERVER["REQUEST_METHOD"] == "POST") {
    $data = ($_POST["data"]);
}
// write it to file
$fileName = "data.txt";
$file = fopen($fileName, "a");
if($file){
    fwrite($file, formatData($data).",");
    fclose($file);
    echo "OK";
}

function formatData($data){
    $arr = unpack('H*', $data);
    return strtoupper(implode(" ", $arr));
}
?>
^ %$ this is to fix the color in Texstudio, ^ is the delimiter


Then using an Android service to keep reading in the background which is the usual approach to deal with long running operations on Android Applications~\cite{android-services}.

The usb-serial-for-android library provides all the necessary to read data from the mini-usb port~\cite{usb-serial-for-android}. The listing~\ref{listing:android_gateway} shows an extract of my code implementing the callback to receive data in directly from the \gls{usb} port.

\putcode{android_gateway}{Android: Callback to receive data from sensor}[language=Java,style=styleprogramming]^
// the parameter data is a binary string from the sensor
@Override
public void onNewData(final byte[] data) {
    if(bufferFrames.isFull()){
        callback.getBuffer(bufferFrames);
        bufferFrames = new BufferFrames();
    }else{
        bufferFrames.addChunk(new Chunk(data));
    }
}
^
% end of code, delimiter is ^
Notice in line 3 that it is in reality quite simple to receive binary data in form of an byte array.


\subsection{LTE Module}
\acrfull{lte} modules work as a phone: They need a \gls{sim} card to connect to network, they can be integrated in a board. Typically these modules have a number of interfaces such as \gls{usb}, rs-232, \gls{spi}, etc to connect peripherals.


In order to set a route between your device and a service on Internet or your own server, a piece of code must be provided, it depends upon the module how can be done. For a project like this it is interesting that the module has its own \gls{tcpip}.



\subsubsection{Gemalto LTE Module}


This is not a simple modem that allows other machines to be connected to Internet, it has a complete \gls{tcpip} stack which means that protocols of the transport layer such as \gls{tcp} and \gls{udp} and application layer such as \gls{http} and \gls{https} can be used as well all in very small compact chip as it is seen in figure~\ref{fig:lte_module}.

	\putimage[5]{lte_module}{ELS61-E chip size}

The module used was Gemalto ELS61-E which is configured using the Hayes command set (also called AT commands) which are used typically on modems. See how AT commands look in listing~\ref{listing:at_commands_example}. %reference.
\putcode{at_commands_example}{AT commands}[style=styleprogramming]$
AT^SMSO  # shutdown
AT+COPS  # register to network command
$ % end of code, delimiter is $


This module can be programmed using \gls{javame} which is a \gls{java} edition for embedded devices \cite{javame}. Application layer protocols and \gls{tcp}/\gls{udp} sockets can be used in a \gls{midlet} which allows to describe the life-cycle of a single application such as in the listing~\ref{listing:midlet-example} example. With this tools the \gls{usb}, \gls{spi} or \gls{rs232} ports can be controlled and even send AT commands.


\putcode{midlet-example}{MIDlet application life-cycle example}[language=Java,style=styleprogramming]^
import javax.microedition.midlet.*;

public class HelloWorld extends MIDlet {
    
    public HelloWorld() {
        System.out.println("Constructor");
    }
    
    /** This is the main application entry point. */
    public void startApp() throws MIDletStateChangeException {
        System.out.println("startApp");
        System.out.println("\nHello World\n");
        destroyApp(true);
    }
    
    /**  Called when the application has to be temporary paused. */
    public void pauseApp() {
        System.out.println("pauseApp()");
    }
    
    /** Here you must clean up everything not handled by the garbage collector. */
    public void destroyApp(boolean cond) {
        System.out.println("destroyApp(" + cond + ")");
        notifyDestroyed();
    }
}
^ % end of code delimeter is ^


For a full list of features of the module refer to \url{http://www.gemalto.com/brochures-site/download-site/Documents/M2M_ELS61_datasheet.pdf}


	\putimage{lte_board}{Lte Module on top of the board to program it}
To do all the communication and configuration with the module there is a board where it can be attached proving micro-usb connectors, antenna, reset button, power among other things see figure~\ref{fig:lte_board}





\subsection{Raspberry Pi}
A Raspberry pi is a credit card sized computer and on its model 3B includes among other things 4 \gls{usb} ports multi-core \gls{cpu}~\cite{rpi3}. Considering that the raspberry comes with a Linux distribution the possibilities are unlimited, for the purposes of this project it is specially handy the possibility of using any programming language and a lot of software packets available.

\putimage{raspberry}{Raspberry Pi Physical appearance}

\subsubsection{The Reader Program}
The programming language chosen to communicate with the sensor from the raspberry pi was \gls{python} since it has a number of libraries available to use. Then it is necessary to point what features are suitable for a program which reads the sensor and open a connection to the server side:
\begin{itemize}
    \item Needs to communicate both ways trough \gls{usb}.
    \item Has to open a connection to the server/cloud continuously and be able to recover. automatically from failures on the network.
    \item Must do all this at same time taking advance of raspberry pi's multiple cores.
    \item Prioritize the sensor read task over the rest, this is the most critical part and must be have a higher priority
\end{itemize}



In order to separate tasks it is possible to use multiple threads which are supported in \gls{python} and although this allows run several tasks at the same time when using python, it could be advisable to use the multiprocessing package to separate tasks into several process and take advantage of the various \gls{cpu} cores~\cite{python-multi}. For controlling process priority the package "psutil" allows to control the "niceness" of the process~\cite{python-psutil}.

In order to get access to the raspberry when it is out of reach, connections to it through Internet using \gls{ssh}, which is a protocol to connect to remote hosts using shell through an encrypted connection. It is also desirable being able to do certain operations remotely without using \gls{ssh}. The connection made between client-server-raspberry can be taken in advance to for example shutdown, reset, update, etc the raspberry. For this purpose the subprocess package can be use to issue commands and other process, as one can do in a terminal shell~\cite{python-subprocess}. See the listing~\ref{listing:rpi-subprocess} on appendix~\ref{appx:reader} to see my actual implementation.

\subsubsection{Services}
To run programs and script automatically from booting it is possible to add systemd based services which can be found in most of Linux distributions. For the purposes of this sensor reader it is needed at least two services. One to keep alive the network connection alive. Other to keep the reader program constantly running. Listing~\ref{listing:rpi-services} show these two services which basically run other script and try to keep it alive.

\putcode{rpi-services}{Systemd services}[language=Bash,style=styleprogramming]^
### /lib/systemd/system/lte.service
[Unit]
Description=Lte module service

[Service]
ExecStartPre=ls /dev/cdc-wdm0 || echo "cannot see the lte module, retrying..."
ExecStart=/home/pi/lte-daemon
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target

### /lib/systemd/system/sensor.service
[Unit]
Description=read sensor and send data via websocket

[Service]
ExecStart=/home/pi/sensor-reader/main.py
WorkingDirectory=/home/pi/sensor-reader
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
^

\section{Client Side Methods}\label{sec:client-application-methods}
On this section it will be described different methods to create a client able to connect to the cloud thus the sensor, present the data to the user and send commands to the sensor.

\subsubsection{Porting the \gls{labview} Application}
At the beginning of the project LeViteZer provided an example application to read the sensor from a laptop made in \gls{labview}, although this works it is not an idea platform to develop since it is strict closed software and in order to work with it a expensive license has to be paid. Then it was agreed that a ported python version will be made from the \gls{labview} client and extends its capabilities beyond the laptop-sensor \gls{usb} connection.

    \putimage{labview}{LabView implementation}
    
\gls{labview} programs are not write in code but using a "visual programming language" based in diagrams similar to circuits were the data flows. It is oriented to instrument control, data acquisition, automation, etc.~\cite{labview}

Although there was not intention to use \gls{labview} for the purposes of this thesis, it does was used to do research about what protocols to use and testing, see figure~\ref{fig:labview-udp} for a simple \gls{udp} client applications which just receives raw binary information from a sensor and displays it alongside the frame number.

    \putimage{labview-udp}{Labview UDP client}

%\subsection{\gls{udp} Java client}
\subsection{Websocket Python Client}\label{sec:websocket-python-client}
This application was intended to have the characteristics of the \gls{labview}'s mentioned on the previous section and provide it with connectivity to a cloud service for remote communication. The application was wrote on python and taking advantage of the multiple libraries that the community offers for free as open source.


\subsubsection{Design}
On a relatively complex application as this one  \gls{oop} is the most convenient way to go when designing the application.

As data sources in this application, it can be from directly \gls{usb} or from network, for those purposes the class "SerialConnection" will be in charge of communicate with a \gls{ir} sensor connected to the computer directly over \gls{usb} (for testing) see listing~\ref{listing:serial-reader} in appendix~\ref{appx:reader}, this class is the same that is used in the raspberry side to read the sensor. On the other hand "WebsocketConnection" mimics roughly the behavior of "SerialConnection" however it makes the connection over Internet using the \gls{ws} protocol.

Once a connection is made the class "Camera" and its children will handle data processing to make array frames as it was explained in section~\ref{creatingimage}.

    \putimage[15]{python-uml}{UML diagram (simplified)}
    
As seen in figure~\ref{fig:python-uml} it shows the most important components of the application and its relations, it can be noticed that there is a separation between \gls{ui} components and logical ones.

\subsubsection{User Interface}
The user interface is implemented using the known \gls{qt} framework which is uses \gls{cpp} but there is a python bindings package to use in a python application without writing a single line of \gls{cpp} code~\cite{riverbank}.

Advantages of using qt are among others:
\begin{itemize}
    \item cross-platform: same code works on any operative system where the framework is available.
    \item it is possible to design the interface using a designer program (see figure~\ref{fig:qt-designer}) and save it as a \gls{xml} file that can be read from the application, saving a lot of time on development stage.
    \item it is a well known framework and there is plenty of information available about it.
\end{itemize}

    \putimage{qt-designer}{QT designer}

The sensor image itself is made using a plotting library named \gls{matplotlib} used in quality scientific plots and animations. \gls{matplotlib}  also provides a back-end to attach the graphics to \gls{qt} among other \gls{ui} frameworks. This can be seen in the \gls{uml} diagram (figure~\ref{fig:python-uml}) where the class "MplCanvas" which presents the frames from the "Camera" inherits from the \gls{matplotlib} class "FigureCanvasQTAgg"~\cite{matplotlibqt4agg}.

    \putimage{python-client}{Python Client Application}
    
As seen in figure~\ref{fig:python-client} the application client has 2 well differenced parts. On the left it is the image displayed as a colored gray-scale image in figure~\ref{fig:ir-image}. \gls{matplotlib} let us apply color maps on the image very easily, also to add an interpolation to improve the image quality, in this case there is a Bicubic interpolation~\cite{matplotlibinter}.

    \putimage[5]{ir-image}{Ir image}

On the left side there is a control panel (figure~\ref{fig:control-panel}) which displays meta-data information and buttons that can send commands to the sensor as described in section~\ref{commands}, on the right of some buttons there are input fields to enter the arguments to the commands that required it alongside the current value of the argument (current argument values are meta-data as well).

    \putimage{control-panel}{Control panel}
    
There is a separate section for special buttons to control a raspberry pi in the case the sensor is connected to a one.


\subsection{Android Client}
During the development of the project I found attractive the idea of having a client application on the phone and after finishing the python client described in the previous section I started to develop a simple but powerful \gls{android} application. It let connect to any camera already registered in the cloud (At this stage the cloud allows multiple sensors see. section~\ref{sec:server-side-methods}).

As in the python client, it is necessary to code:
\begin{itemize}
    \item a class to connect to server or cloud through \gls{ws}.
    \item create the image from the data.
    \item allow to choose which camera to connect to.
\end{itemize}

\gls{android} application are slitted on different screens called Activities which contain \gls{ui} elements that the user can interact. In this case there is an activity for choosing the camera to connect, see figure~\ref{fig:android-client3}.

    \putimage[16]{android-client3}{Android Client}

The other activity makes the a \gls{ws} connection and process the data in real time so the different frames can be visualized in gray-scale (figure~\ref{fig:android-client3}).

To achieve this \gls{android} allows to extend \gls{ui} elements with new behavior. In this case "ImageView" class is extended to add a \gls{ws} connection and fill the image with an array of binary data from this connection (same than in the python application section~\ref{sec:websocket-python-client}), in listing~\ref{listing:cameraview} the "CameraView" class meets this behavior using "WebsocketConnection" to get data from sensors (listing~\ref{listing:websocketconnection}) and "HighCamera" to represent a frame of the image (listing~\ref{listing:highcamera}). All of these listing can be found in appendix~\ref{appx:androidclient}.


\section{Server Side Methods}\label{sec:server-side-methods} 
On this section describes the different approaches tested to created the middle point between sensors and clients. The server side application must be hosted somewhere, in this case a cloud environment described in the next section.

\subsection{The Communication Channel}\label{sec:the-communication-channel}
Regardless what technology it is used for coding, build and maintain the cloud application, and before start coding it should define how different components are related between each other.
Let’s start by defining the following entities:
\begin{itemize}
    \item Sensor: It represents a single sensor connected to a raspberry pi, although it could a normal computer. The sensor itself does not connect to networks, thus it needs a middle hardware but it is considered as whole “entity” here.
    \item Client: A client can be anything that can connect to a sensor by \gls{http} request. A desktop computer, a smartphone, etc. The client must create frames from sensor and send commands using a \gls{ws}.
    \item Cloud: It is what holds all the sensor entities and their clients on it.
    The channel should support an unlimited number of sensors which can hold an unlimited number of clients.
\end{itemize}
\putimage[15]{channel-er}{\acrlong{er} of the communication channel}
The channel should support an unlimited number of sensors which can hold an unlimited number of clients.
The diagram in figure \ref{fig:channel-er} represents the general view of how entities are related to each other. This helps to develop a \gls{uml} Class Diagram which specifies how classes in an \gls{oop} language are related to each other. In figure~\ref{fig:channel-uml} there is such diagram simplified.
On the final implementation the server side application was written in \gls{js} which is the Language for \gls{nodejs} applications.
\putimage[15]{channel-uml}{\gls{uml} diagram}



\subsection{Python Flask}
Flask is a \gls{python} framework for web development which allows to write web applications back-ends and is specially useful to create web \gls{api}s. this application use an \gls{http} approach as described in section~\ref{sec:http} to communicate client side and sensor side applications must implement the mentioned approach as well.

This keeps a queue buffer of image data and commands, so that both sensor and client have to request continuously even though when there is no new data. In listing~\ref{listing:flask} a simplification of this Flask application is shown, the buffer and commands are hold in the \texttt{data\_queue} and \texttt{parameters}.

\putcode{flask}{\gls{http} - buffer approach}[language=Python,style=styleprogramming]^
app = Flask(__name__)
parameters = {}
data_queue = Queue(5)

@app.route('/video/buffer', methods=['POST'])
def submit_buff():
    data = request.data
    logging.debug("data:%s", data)
    if data_queue.full():
        logging.debug('queue is full. dropping 1')
        data_queue.get() # drop 1 buffer
    
    data_queue.put(data)
    return jsonify(**parameters)


@app.route('/video/buffer', methods=['GET'])
def obtain_buff():
    global parameters
    print request.args
    for k, v in request.args.items():
        parameters[k] = v
        
    if data_queue.empty():
        logging.debug('queue is empty, sending 0 ...')
        return '0'
    else:
        return data_queue.get()
^
Using the \texttt{/video/buffer} endpoint it is possible to send data to it using a 'POST' \gls{http} requests continuously from the sensor side and to send 'GET' requests to get image data in the client side, if a client wants to send a command (called parameter in this application) it can be sent as query parameter in the 'GET' request, for example \texttt{www.example.com/video/buffer?command0=value0\&command1=value1\&...}

A good thing about flask is its straightforward \gls{api} as seen in listing~\ref{listing:flask}, defining a route to an endpoint is very easy because takes advantage of the decorators \texttt{@app.route} and result in a quite clear code.

\subsection{\gls{nodejs} Server Application}
\gls{nodejs} is a \gls{js} runtime which allows to create server-side applications, the main reason of why one would choose \gls{nodejs} over other well know options such as \gls{apache} + \gls{php} is the non-blocking model \gls{nodejs} is based on. This let make asynchronous code easily and it is quite fast~\cite[p.12]{nodejs}~\cite{nodeblocking}.
In addiction to this there are other options to consider working with \gls{nodejs}:
\begin{itemize}
    \item It has big community.
    \item It has likely the biggest open source library on Internet, accessible through \gls{npm}.
    \item most of cloud providers offer it out of the box.
    \item It is very easy to start up and configure unlike options.
\end{itemize}
To work with both \gls{ws} and \gls{http} protocols in a \gls{nodejs} application it is possible to use these quite well know open source libraries:

\begin{itemize}
    \item ws. It is claimed to be the fastest \gls{ws} library \url{https://www.npmjs.com/package/ws}
    \item Express. Lightweight web framework for node. Probably the most used node web framework \url{https://www.npmjs.com/package/express}
\end{itemize}
Although this libraries are focused for web applications the clients described in section~\ref{sec:client-application-methods} do not need \gls{html} characteristics . However in the future a \gls{html} client application could be developed using the \gls{api} of this \gls{nodejs} application.

Since both protocols must be listen the same port, a \gls{http} server must be created using express then integrating it with the \gls{ws} one and finally listening to the desired port, see listing~\ref{listing:nodejs-example}.

\putcode{nodejs-example}{html and websocket server}[language=JavaScript, style=styleprogramming]$
const express = require('express');
const WebSocket = require('ws');
const http = require('http');

const port = process.env.PORT
const ip = '0.0.0.0';

/* http server */
const express = express();
const server = http.createServer(express);
    // ... handle http requests ...

/* websocket server extends the http server */
var wss = new WebSocket.Server({
    server: server,
    // other websocket configuration ...
});

 wss.on('connection', function connection(ws) {
    // ... handle websocket requests ...
});

server.listen(port, ip);
$

Express and ws have events to handle the connections using callbacks to for any behavior one wants to add.

A complete view of the main file application can be consulted in appendix~\ref{appx:nodejsapp} listing~\ref{listing:nodejsmain}



\section{Testing Methods}
Testing is an important part of Software development process it gives insight about the quality and how much the software is error-prone, however creating test and maintaining after refactoring it is also a time consuming practice and since this project is carried out by one person rather than a team of developers there were added test only in the server-side of the whole communication system.

\subsection{Unit Testing}
Unit Testing is about testing modules or units which are single pieces of software that should work independently of others. In \gls{oop} this is usually a class, but it could be a single function or method. It is the developer who should define what is a single unit.
\subsection{Acceptance Testing: Robot Framework}
In order to test the server-side application with arbitrary number of clients and sensors with different configuration and backgrounds an acceptance testing approach is very convenient; acceptance testing features a more structured and complex way of testing which allows a efficient way of pinpointing application failure, automation and reusability~\cite{bisht2013robot}.

For this purpose Robot Framework is a great tool, it is a open source for general purpose test automation. It is very flexible and it allows create test using a human friendly keywords and generate complete reports and logs about the test results. It can also be extended by adding existing libraries or creating them using \gls{python} or \gls{java}~\cite{robotframe}.
A simple test file can be seen in listing~\ref{listing:robot-example}

\putcode{robot-example}{A example of robot framework}[style=styleprogramming]$
Documentation     A test suite with a single test for valid login.
Resource          resource.txt

*** Test Cases ***
Valid Login
Open Browser To Login Page
Input Username    demo
Input Password    mode
Submit Credentials
Welcome Page Should Be Open
[Teardown]    Close Browser
$

Using the libraries already in the client python application in section~\ref{sec:websocket-python-client} and the Robot Framework \gls{api} I created a library to test \gls{ws} connections. Those connection are held in an array, created and deleted for every single test, see listing~\ref{listing:robotlib} for the whole library code in the appendix~\ref{appx:nodejsapp}.

The library provide keywords like the ones in the listing~\ref{listing:robot-example} but a group of test cases have to be defined in addiction to define some local keywords to reuse behavior. see listing~\ref{listing:robottest} in appendix~\ref{appx:nodejsapp} for all test cases defined to test the server-side application. On this file it can be noticed several sections between triple asterisks:
\begin{itemize}
    \item Variables. To define global variables which syntax is "\texttt{\$\{variable\_name\}}".
    \item Settings. Define libraries which in addiction to my own \gls{ws} library there is also other to run processes, invoke operative system commands, \gls{http} requests, etc. Provide actions at beginning and the end of every test or even at the beginning and end of the whole test suite.
    \item keywords. Here it is defined custom keywords out of other keywords, they can accept arguments and return values.
    \item Test Cases. The last section show every test case. At the end will be shown either if the test was passed or failed.
\end{itemize}

After the execution of tests an \gls{html} report file is generated (figure~\ref{fig:test-report}) along to a log one (figure~\ref{fig:test-log})

    \putimage[14]{test-report}{Test Report}
     
The Report is general view of what happened during the test execution.
     
    \putimage[14]{test-log}{Test Logs}
    
The log file contain a more detailed information about the tests.



\section{Cloud methods}
While the Server Side methods section~\ref{sec:server-side-methods} describes the application itself, it does not tell anything about where and how to host the code so that it is available everywhere from Internet.

"The cloud" is quite a broad concept which usually includes different service models as \gls{saas} which are hosted applications accessible from client applications, \gls{paas} which provides services for developers to create applications such as \gls{saas} ones, however the developer do not have access to the cloud infrastructure like the servers or the network, \gls{iaas}. Similar to \gls{paas} but with more control over the platform~\cite{petermelltimothygrance2011}.
%\subsection{Google Cloud}
\subsection*{OpenShift and Docker}
OpenShift is a platform for the deployment of web applications and services. It takes advantage of technologies such as \gls{kubernetes} and \gls{docker} to run and manage application in containers~\cite{shipley2016openshift}. Nokia (which collaborates actively in this project) provides \gls{paas} as part of their Nokia Innovation Platform which aims to create solutions for \gls{iot}~\cite{nokiainnovation}.

The process of updating the server side application is through a OpenShift mechanism called \gls{s2i} which allow creating containers from the application source code without using \gls{docker} files, it its simplest form a developer provides a \gls{git} repository to the platform and OpenShift takes cares of everything: building, deploying, routing, etc~\cite[5]{shipley2016openshift}.


%\subsection{Communication sensor-client}
%% TODO: \subsection{Communication sensor-client}
%\putimage{communication_udp}{Diagram of the communication using the module and UDP}

\section{Other Tools Used}

\subsection{Control Version}
On any serious software development project there must be a \gls{cvs} which allows keep tracking of any changes in the code (or other files) and reversed if necessary. On this project the popular control version tool "Git" was used, which has many features but the one that makes it more special is its decentralized repository model which means that every repository copy has all the history changes.

All the repositories to the applications developed in this thesis are hosted in \gls{github} which it is perfect for sharing or publish open source projects.

\subsection{Latex}
% What is latex, what is tex
% reasons to use latex, abreviations, commands etc, show figures
To write this thesis \LaTeX was used which is a documentation preparation system rather than using the mainstream options which are LibreOffice or Office Word. The reasons for this was automation and the quality that can achieve.

    \putimage{latex-look}{How the document looks like}
    
In figure~\ref{fig:latex-look} it can be observed how the code looks like, it is just raw text with no style at all and it has to be compiled to generate a \gls{pdf} document.
%\subsection{IDE}
%Pycharm
%Visual Studio Code

\clearpage\chapter{Results}\label{sec:results}
%What was found/created/designed/produced?
The results of this thesis is a set of pieces of software which together form the communication channel, being its central part the server-side hosted in cloud accessible through the web \gls{api} described on section~\ref{sec:web-api}.



\section{Software}\label{sec:software}
After solving some bugs in the server-side and the raspberry pi part the communication system can work continuously 24 hours a day with several cameras as 5.4.2017 the longest test in a sensor in the system has been 4 days and 19 hours. In figure~\ref{fig:multi-camera} can be seen a client application with sensors on different locations.

     \putimage{multi-camera}{Multiple sensors connected to a single client}

As stated in chapter~\ref{sec:methods-and-materials} all the code is in \gls{github} repositories, here is a list with every repository for most of the software developed in this project.


\begin{itemize}
    \item \gls{android} client application: \url{https://github.com/alvaro893/android-ir-sensor-client}
    \item Server-side \gls{nodejs} application: \url{https://github.com/alvaro893/cloud_websocket}
    \item Python client application: \url{https://github.com/alvaro893/sensor_reader}
    \item Sensor Reader application on raspberry pi side: \url{https://github.com/alvaro893/sensor-reader/tree/raspberry}
    \item This Thesis: \url{https://github.com/alvaro893/bachelors-thesis}
\end{itemize}

The code shown in the appendixes is in these repositories and up-to-date.


\section{Web \gls{api}} \label{sec:web-api}
In order to provide communication with both sensors and clients a web \gls{api} can be the most convenient way to expose the services of the application providing certain endpoints to register sensors, clients and to access information about the application itself, the information retrieved is in \gls{json} format.

The endpoints are defined as \gls{uri}s. A complete \gls{uri} looks like this:
\begin{quote}
    \texttt{<protocol>://<domain>:<protocol><path>?<parameters>}
\end{quote}

Domain is provided by the cloud service, if the server-side application is running locally in a personal computer domain is "localhost". Paths accepted by the \gls{api} are shown in table~\ref{table:api}

\begin{table}[h]
    \centering
    \begin{tabu}{| l | c | c |}
        \hline
        \rowfont[c]{\bfseries} path & protocol & description \\ \hline
        
        \texttt{/client} & \gls{ws} 		 & Register a client \\
        \texttt{/camera} & \gls{ws}  	 & Register a sensor \\
        \texttt{/cams} 	& \gls{http} GET & receive a \gls{json} of information  \\
        
        \hline
    \end{tabu}
    \caption{Endpoints of the web \gls{api}}
    \label{table:api}
\end{table}

\texttt{/client} and \texttt{/camera} parameters also accept query parameters shown in table~\ref{table:apiarguments}.

\begin{table}[h]
    \centering
    \begin{tabu}{| l | c | c |}
        \hline
        \rowfont[c]{\bfseries} parameter & type & description \\ \hline
        
        \texttt{pass} 		& alphanumeric & password to access \\
        \texttt{camera\_name} & alphanumeric & camera to connect or to register \\
        
        \hline
    \end{tabu}
    \caption{parameters of the web \gls{api}}
    \label{table:apiarguments}
\end{table}

For example \texttt{ws://localhost:8080/camera?pass=d8n2d0\&camera\_name=corner-camera}

\section{Discarded Methods}

\subsection{Android Smartphone Gateway Solution}
This method was purely to test the sensors and to seek for a suitable network protocol rather than as a serious solution for the purposes of this thesis, nevertheless the outcomes were satisfactory and opened the door to a deeper understanding on how \gls{usb} communication can work using a High level language as \gls{java}.

\subsection{LTE Module Solution}
This method could have been the ideal solution to read a sensor and connect it to Internet, but there were multiple issues regarding this method:
\begin{itemize}
    \item It turned out that the module did not support the \gls{lte} frequency bands of the mobile provider Netleap see section~\ref{sec:the-medium} of chapter~\ref{sec:theoretical-background}.
    \item It was hard to set-up a developing environment for it.
\end{itemize} 

\subsection{UDP Protocols}
There were many test to use \gls{udp} for communications but for the issues mentioned in section~\ref{sec:port-issues-on-remote-hosts} of chapter~\ref{sec:theoretical-background} and because \gls{ws} worked very good. any \gls{udp} was dropped.

\subsection{Python Flask Server-Side Application}
At the end the \gls{nodejs} application turned out to work better and faster. so the flask application was not further developed.


\clearpage\chapter{Discussion}\label{sec:discussion}
%What do the results mean?
On this chapter is discussed how the results may be used, specially alongside Computer Vision. The sections here are more based on speculation rather than experimentation and proposed lines of research.

\section{Use in the Nokia Innovation Platform}\label{sec:use-in-the-nokia-innovation-platform}
The Nokia Innovation Platform is a trial environment for teams and star-ups that are related to \gls{iot} projects specially projects that use cell-phone network as \gls{lte}. This project is part of the Nokia Innovation Platform hence there is some ongoing use cases. Some of the sensors has been placed on different places to test its functionality and investigate further the uses of this communication channel.

	\putimage{people}{People in a room}
	
On the figure~\ref{fig:people} some people can be seen clearly and in the figure~\ref{fig:analysed} is shown the same situation plus running a Computer Vision software to detect how many people in the room.

	\putimage{analysed}{Analyzed image to detect heat points in the room}

Computer vision can be used to track people and research their behavior storing big amounts of tracking data may allow to make predictions of many sorts. On the next sections some scenarios are proposed where this could be useful.

On crowded surfaces such as shopping centers, stadiums, summer festivals may be useful to observe patterns and even detect or predict dangerous situations. This is an interesting research topic and could be a continuation of this final year project.


\section{Use in Health Care}
In this section different uses in health care of the sensor communication channel will be discussed. As mentioned on the introduction chapter~\ref{sec:introduction} these sensors do not capture light but heat, thus making patients impossible to recognize from a distance, this can be considered an advantage since most of the people do not feel comfortable with the idea of being watched or video-recorded. Also when using Computer Vision techniques an \gls{ir} image can be easier for a computer to "understand" in other words to analyze especially when it is possible to add limits to the maximum and minimum temperature so that a range of temperature can be interesting while the rest is removed. figure~\ref{fig:setminimum}.
    
    \putimage{setminimum}{Minimum set to human temperature}

On table~\ref{table:commands} in chapter~\ref{sec:methods-and-materials} the available commands to the sensor are shown, we can set maximum and minimum temperatures or make it back to automatic.

    \putimage{2bit}{2bit version of the image}

In addiction to set the minimums and maximums it is possible to change the bit density of the image so we get less data and probably making the image analysis a little easier as it is shown in figure~\ref{fig:2bit}.

Another approach could be use \gls{ir} image to see things that usually are not visible at a glance like for example veins and arteries as seen in figure~\ref{fig:vein}.

	\putimage{vein}{arteries and veins in human arm}
	
Unfortunately on this thesis it were not enough time to do a proper research of health care uses. Nevertheless on the next sections there is some propositions to for further investigation.

\subsection{Bed Patient Care}
A use case may be for monitoring patients on bed, either hospital or home bed. Using image analysis software nurses or doctor could obtain data from multiple patients at the same time. since the sensors can detect heat this could trigger some alarm on high temperature or if the patient is missing for a long period of time.

Also as discussed in previous sections it may be interesting to seek patterns how a patients moves through time and even how long patients are not in bed.

    \putimage{fiber-detector-prototype}{Analysis program prototype}
    
In the figure~\ref{fig:fiber-detector-prototype} we can see a prototype with temperature graphics and other indicators.
    
\subsection{Nursing Homes / Psychiatric Hospitals}

The same principle discussed in section~\ref{sec:use-in-the-nokia-innovation-platform} may be applied to nursing or residential homes where there is a number of people inside a room or outside in a backyard. Then trough Computer Vision it can be detected how many persons there are, if someone is too still or passed out, etc. This detection could trigger certain alarms which will warn the caretakers in the facility

As in nursing homes, psychiatric hospitals could have this kind of system. It could detect potential dangerous situations in this case.


\section{Other Uses}
\subsection{Self-driven Vehicles}
Self-driven public transport vehicles could benefit with this system too, since that there is no driver nor any other worker on the vehicle, accessible remotely \gls{ir} sensor can give valuable data to an hypothetically station in charge of the security of such vehicles and trigger an alarm in case of any dangerous situation.

    \putimage{robo-bussi}{self-driven bus in Otaniemi}
    
On figure~\ref{fig:robo-bussi} is the "Robot bus" moving around Otaniemi campus in Espoo.

\subsection{General Surveillance}
Surveillance is usually help by regular light based cameras plus sometimes some \gls{ir} LEDs which allows them see during night time, However since humans emit heat they can be easily spotted with \gls{ir} sensors instead.

\section{Possible Additions in the Future}
\subsection{3D Heat Map Using Multiple Sensors}
When using several sensors, it could be possible to create 3D heat map with all the data similar to figure~\ref{fig:heatmap}.

    \putimage[10]{heatmap}{Heat map concept}
    
This can be used to have a better understanding of how heat behaves in a particular area.

\subsection{HTML5 Application}
Since this project uses already web technologies such as \gls{ws} it will not difficult to create an \gls{html}5 client application for connecting to the different sensors able to do the same as the python client, however the user does not need to install anything to make it work, only an up to day Internet browser.

\subsection{Using RTP to Broadcast Video to Clients}
The server-side application could be extended to support \gls{udp} protocols as \gls{rtp} which can be used to multi-cast video stream to a big number of clients that for example need the video image but no control the sensor~\cite[298]{hardy2013networks}. Commands can be still sent through \gls{ws} 

\clearpage\chapter{Conclusions}
%This section usually begins with a restatement of the goal of the project, and includes
%a brief summary of the key results of the project and a conclusion about the
%significance and implications of the results, for your client and perhaps the field in
%general. Also mention strengths and limitations of the project and ways in which the
%project could be changed and improved if carried out again. In the end recommend
%further action, such as further study, if relevant.
%Keep this section short (a few paragraphs, no subheadings), tie in and highlight the
%main points of the project and its results and draw a clear conclusion.
As an \gls{iot} project the purpose of this thesis was to find an effective communication channel between \gls{ir} sensors and clients, in other words, to create a system where clients can control these sensors and receive data simultaneously. The result was a complete communication system:
\begin{itemize}
	\item A sensor-side: which includes a \gls{python} application to read the sensor in a Raspberry Pi and service scripts to keep alive the connection to both the network and the Sensor.
	\item A server-side: that uses cloud technologies offered by Nokia and also includes a \gls{nodejs} application that keeps sensors and clients connected.
	\item A client-side: which includes a \gls{python} client application and an \gls{android} application able to connect to online sensors and control them.
\end{itemize}
 So far there are some sensors running on Nokia headquarters to test their usability.
 
 Either LeViteZer and Nokia members have shown quite satisfied with the results and willing to continue working on this project beyond the scope of this thesis.
 
 One of the distinctive things about the communication protocol on this project is the use of \gls{ws} outside a web browser which has been proven to work exceptionally good, better than expected. Also with this comes some limitations since \gls{ws} is not the best way to broadcast image from sensors to big sets of clients and that is something to be improved.

 It was intended to deepen more on the use cases especially on well-being services, unfortunately there was no time for more research on this. Perhaps other students' thesis might continue this part.



%----------------------------------------------------------------------------------------
%   BIBLIOGRAPHY 
%----------------------------------------------------------------------------------------

\clearpage\IfLanguageName{finnish}{\bibliographystyle{vancouver_fi}}{\bibliographystyle{vancouver}}
%line space
%\singlespacing %removed otherwise the appendix are also single space
\begin{flushleft}
\begin{singlespacing}
\bibliography{biblio}
\end{singlespacing}
\end{flushleft}

%----------------------------------------------------------------------------------------
%   ACKNOWLEDGMENTS 
%----------------------------------------------------------------------------------------
\clearpage\chapter*{Acknowledgments}
I want to thank to Jukka Honkaniemi and Tero Nurminen (Metropolia) for let me be part of this project and their guidance. Also I want to Thanks to Kim Janson (LeViteZer) for all I learn during last months in this project.

%for conting the pages
\label{LastPage}~


%----------------------------------------------------------------------------------------
%   APPENDICES 
%----------------------------------------------------------------------------------------
%avoid that the last page of bib get appendix header
\clearpage
%start appendix
\appendix
%no page number for appendix in table of content
\addtocontents{toc}{\cftpagenumbersoff{chapter}}
%appendix sections and subsections not in table of content
\settocdepth{chapter}
%add "Appendices" in the table of content
\addappheadtotoc
%force smaller vertical spacing in table of content
%!!! There can be some fun depending if the appendices have (sub)sections or not :D
% You will have to play with these numbers and eventually copy the \pretocmd line on before some \chapter and force another number.
\addtocontents{toc}{\vspace{11pt}}
\pretocmd{\chapter}{\addtocontents{toc}{\protect\vspace{-24pt}}}{}{}
%have Appendix 1 (instead of Appendix A)
\renewcommand{\thechapter}{\arabic{chapter}} 

\newcommand\liite[1]{
%each appendix restart page num to one
\setcounter{page}{1}
%special counter for appendix TODO: this is a ugly quick hack :( Should find a better way to count the page per appendix.
\newtotcounter{appx#1}
%overwrite the header
\makeevenhead{plain}{}{}{\appname \thechapter \\ \thepage\,(\stepcounter{appx#1}\total{appx#1})}
\makeoddhead{plain}{}{}{\appname \thechapter \\ \thepage\,(\stepcounter{appx#1}\total{appx#1})}}

\liite{1}



\chapter{Sensor Reader Listings}\label{appx:reader}

\addtocontents{toc}{\vspace{11pt}}

\begin{lstlisting}[label={listing:serial-reader},caption={Serial Reader Class},language=Python, style=styleprogrammingappendix]
import thread
import logging
import psutil
from multiprocessing import Process
from serial import Serial, SerialException
from Constants import VERY_HIGH_PRIORITY, HIGH_PRIORITY

class Serial_reader(Serial):
"""" This class read data from sensor in a Thread """
    def __init__(self, pipe, port):
        Serial.__init__(self, port=port, baudrate=115200)
        self.pipe = pipe
        self._start_process()
    
    def _start_process(self):
        process = Process(name="SerialProcess", target=self._run, args=())
        process.daemon = True
        process.start()
        try:
            psutil.Process(process.pid).nice(VERY_HIGH_PRIORITY)
        except psutil.AccessDenied as e:
            psutil.Process(process.pid).nice(HIGH_PRIORITY)
    
    def _get_data(self):
        one_byte = self.read(1)
        n_bytes = self.in_waiting
        return one_byte + self.read(n_bytes)
    
    def _send_data(self):
        while self.is_open:
            print "waiting for commands"
            data = self.pipe.recv()
            print data
            self.write(data)
    
    def _run(self):
        thread.start_new_thread(self._send_data, ())
        while self.is_open:
            try:
                data = self._get_data()
                self.pipe.send(data)
            except SerialException as e:
                logging.error(e.message)
                self.stop()
                break
    
    def stop(self):
        if self.is_open:
        self.close()

\end{lstlisting}\vspace{14pt}

\begin{lstlisting}[label={listing:rpi-ws},caption={Websocket Class},language=Python, style=styleprogrammingappendix]
import logging
import thread
from websocket import WebSocketApp, ABNF
from Constants import URL, CAMERA_PATH, PARAMETERS

class WebSocketConnection(WebSocketApp):
    def __init__(self, pipe, url=URL + CAMERA_PATH + PARAMETERS):
    WebSocketApp.__init__(self, url,
    on_message=self.on_message,
    on_error=self.on_error,
    on_close=self.on_close,
    on_open=self.on_open)
    self.open_connection = False
    self.pipe = pipe
    
    def on_message(self, ws, message):
        logging.warn("received command:%s, %d bytes", message[0], len(message))
        self.pipe.send(message)
    
    def on_error(self, ws, error):
        logging.error(error)
    
    def on_close(self, ws):
        self.open_connection = False
        logging.warn("### closed ###")
    
    def on_open(self, ws):
        self.open_connection = True
        logging.warn("opened new socket")
    
        def run():
            while (self.open_connection == True):
                data = self.pipe.recv()
                self.send_data(data)
        
        thread.start_new_thread(run, ())
    
    def stop(self):
        self.open_connection = False
    
    def send_data(self, data):
        if self.open_connection and len(data) != 0:
        self.send(data, opcode=ABNF.OPCODE_BINARY)
        
    def set_pipe(self, pipe):
        self.pipe = pipe
\end{lstlisting}\vspace{14pt}

\begin{lstlisting}[label={listing:rpi-subprocess},caption={Subprocess example},language=Python, style=styleprogrammingappendix]
from thread import start_new_thread
from subprocess32 import call
import logging

def shutdown():
    run_command_async("/sbin/poweroff")

def reboot():
    run_command_async("/sbin/reboot")

def update():
    run_command_async("./build.sh")

def test():
    run_command_async("sleep", "3")

commands = {
'rs': shutdown,
'rr': reboot,
'ru': update
}

def run_command_async(*args):
    def run(*args):
        result = call(args)
    
    start_new_thread(run, args)


def is_raspberry_command(s):
""" Check this is a command for the raspberry rather than the sensor. First letter must be an 'r'"""
    if s[0] == 'r':
        command = commands.get(s)
        if callable(command):
            command()
        else:
            logging.warn("command not found: %s" % s)
            return True
    else:
        return False



\end{lstlisting}\vspace{14pt}

%\clearpage
%\liite{2}
%
%% TODO: Python client appendix
%\chapter{Python Client listings}\label{appx:pythonclient}
%\addtocontents{toc}{\vspace{11pt}}



\clearpage
\liite{2}

\chapter{Android Client listings}\label{appx:androidclient}
\addtocontents{toc}{\vspace{11pt}}

\begin{lstlisting}[label={listing:cameraview},caption={CameraView class, extending ImageView},language=Java, style=styleprogrammingappendix]
package es.alvaroweb.ircamerareader.wscameraview;

import android.content.Context;
import android.graphics.Bitmap;
import android.graphics.Canvas;
import android.graphics.Color;
import android.support.annotation.Nullable;
import android.util.AttributeSet;
import android.util.Log;
import android.view.View;
import android.support.v7.widget.AppCompatImageView;
import java.util.Random;
import okio.ByteString;

/**
* Copyright (C) 2016 Alvaro Bolanos Rodriguez
*/

public class CameraView extends AppCompatImageView implements WebsocketConnection.OnReceiveRow, HighCamera.FrameCallback, View.OnClickListener {
    
    private static final String DEBUG_TAG = CameraView.class.getSimpleName();
    private static Random random = new Random();
    private Bitmap bitmap;
    private int sizex = 160;
    private int sizey = 120;
    private WebsocketConnection websocketConnection;
    private HighCamera highCamera;
    private Runnable t;
    private boolean reversed = true;
    
    
    public CameraView(Context context) {
        super(context);
        initBitmap();
    }
    
    public CameraView(Context context, @Nullable AttributeSet attrs) {
        super(context, attrs);
        initBitmap();
    }
    
    private void initBitmap() {
        bitmap = Bitmap.createBitmap(sizex, sizey, Bitmap.Config.ARGB_8888);
        highCamera = new HighCamera(this);
        this.setOnClickListener(this);
    }
    
    @Override
    protected void onDraw(Canvas canvas) {
        super.onDraw(canvas);
        // Bitmap has to be set here. and this callback is called from UI
        this.setImageBitmap(bitmap);
    }
    
    
    public void setImage(byte[][] array) {
        boolean dimensionMaches = array[0].length == bitmap.getWidth() &&
        array.length == bitmap.getHeight();
        
        if (!dimensionMaches) {
            Log.d("image", "doesn't match the dimension");
            return;
        }
        
        for (int i = 0; i < bitmap.getHeight(); i++) {
            for (int j = 0; j < bitmap.getWidth(); j++) {
                int pixel = convertByteToInt(array[i][j]);
                if (reversed) {
                    bitmap.setPixel(j, bitmap.getHeight() - i - 1, Color.rgb(pixel, pixel, pixel));
                } else {
                    bitmap.setPixel(j, i, Color.rgb(pixel, pixel, pixel));
                }
            }
        }
    }
    
    public void setRandomImage(View view) {
        byte[][] arr = new byte[sizey][sizex];
        for (int i = 0; i < sizey; i++) {
            for (int j = 0; j < sizex; j++) {
                arr[i][j] = ((byte) randint(Byte.MIN_VALUE, Byte.MAX_VALUE));
            }
        }
        setImage(arr);
    }
    
    public void cleanImage() {
        for (int i = 0; i < bitmap.getWidth(); i++) {
            for (int j = 0; j < bitmap.getHeight(); j++) {
                bitmap.setPixel(i, j, Color.rgb(255, 255, 255));
            }
        }
    }
    
    private int convertByteToInt(byte b) {
        return b & 0xff;
    }
    
    private int randint(int min, int max) {
        return random.nextInt(max + 1 - min) + min;
    }
    
    public void connectTo(String uri) {
        Log.d(CameraView.class.getSimpleName(), "uri received: " + uri);
        websocketConnection = new WebsocketConnection(uri, this);
    }
    
    public void stopWebsocket() {
        websocketConnection.close();
    }
    
    @Override
    public void receiveRows(ByteString data) {
        if (data.size() < 1) {
            return;
        }
        highCamera.consumeData(data);
    }
    
    @Override
    public void frameReady(byte[][] frame) {
        this.setImage(frame);
    }
    
    
    @Override
    public void onClick(View view) {
        reversed = !reversed;
    }
    
    public interface UpdateArray {
        void updateArray();
    }
}
\end{lstlisting}\vspace{14pt}

\begin{lstlisting}[label={listing:highcamera},caption={HighCamera class, represents a frame},language=Java, style=styleprogrammingappendix]
package es.alvaroweb.ircamerareader.wscameraview;

import android.util.Log;
import com.google.common.primitives.Bytes;
import java.util.Arrays;
import java.util.LinkedList;
import java.util.List;
import okio.ByteString;

/**
* 00 01 02 04 ------
Data is arranged on 240(0xF0) rows of 84 bytes(FF FF FF n_row and 80 of data):
FF FF FF 01 <DATA>
FF FF FF 02 <DATA>
FF FF FF 03 <DATA>
...
FF FF FF F0 <DATA>
FF FF FF <TELEMETRY> (38 Bytes)
Where the 4th byte is the number of the row
Every row of the actual picture has 2 rows of the raw data
so the image is 160 x 120 (20198 Bytes)
*/

public class HighCamera {
    private static final int TELEMETRY_ROW_NUMBER = 240;
    private static final int BYTES_IN_ROW_NUMBER = 81;
    private static final String DEBUG_TAG = HighCamera.class.getSimpleName();
    
    private byte[][] frame;
    FrameCallback frameCallback;
    private byte[] remains;
    private byte[] delimiter = new byte[]{-1,-1,-1};
    
    public HighCamera(FrameCallback callback) {
        frame = new byte[120][160];
        frameCallback = callback;
        remains = new byte[]{};
    }
    
    public void consumeData(ByteString data){
        
        List<byte[]> pieces = delimiterData(Bytes.concat(remains, data.toByteArray()), delimiter);
        
        int lastIndex = pieces.size() - 1;
        for(int i = 0; i < pieces.size(); i++){
            if(i == lastIndex) continue;
            processRow(pieces.get(i));
        }
        remains = pieces.get(lastIndex);
    }
    
    
    public void processRow(byte[] row){
        if(row.length < BYTES_IN_ROW_NUMBER){
            return;
        }
        int rowNumber = byteToInt(row[0]);
        Log.d(DEBUG_TAG, "rownumber:"+rowNumber);
        if (rowNumber < TELEMETRY_ROW_NUMBER){
            getFrameData(rowNumber, row);
        }else{
            getTelemetryData(row);
        }
    }
    
    private void getTelemetryData(byte[] row) {
        // todo telemetry
        frameCallback.frameReady(frame);
    }
    
    private void getFrameData(int rowNumber, byte[] row){
        for(int i = 0; i < BYTES_IN_ROW_NUMBER - 1; i++){
            int ind = i + 1;
            int frameRow = rowNumber / 2;
            int frameCol = rowNumber % 2 * (BYTES_IN_ROW_NUMBER -1)+ ind;
            try{
                frame[frameRow][frameCol] = row[ind];
            }catch (ArrayIndexOutOfBoundsException e){
                Log.e(DEBUG_TAG, e.getLocalizedMessage());
            }
        }
    }
    
    private int byteToInt(byte b){
        return b & 0xff;
    }
    
    
    private List<byte[]> delimiterData(byte[] array, byte[] delimiter) {
        List<byte[]> byteArrays = new LinkedList<>();
        if (delimiter.length == 0) {
            return byteArrays;
        }
        int begin = 0;
        
        outer:
        for (int i = 0; i < array.length - delimiter.length + 1; i++) {
            for (int j = 0; j < delimiter.length; j++) {
                if (array[i + j] != delimiter[j]) {
                    continue outer;
                }
            }
            byteArrays.add(Arrays.copyOfRange(array, begin, i));
            begin = i + delimiter.length;
        }
        byteArrays.add(Arrays.copyOfRange(array, begin, array.length));
        return byteArrays;
    }
    
    interface FrameCallback{
        void frameReady(byte[][] frame);
    }
}
\end{lstlisting}\vspace{14pt}

\begin{lstlisting}[label={listing:websocketconnection},caption={WebsocketConnection class, makes a websocket connection},language=Java, style=styleprogrammingappendix]
package es.alvaroweb.ircamerareader.wscameraview;

import android.util.Log;
import okhttp3.OkHttpClient;
import okhttp3.Request;
import okhttp3.Response;
import okhttp3.WebSocket;
import okhttp3.WebSocketListener;
import okio.ByteString;


/**
* Copyright (C) 2016 Alvaro Bolanos Rodriguez
*/

public class WebsocketConnection extends WebSocketListener {
    private static final String DEBUG_TAG = WebsocketConnection.class.getSimpleName();
    private final WebSocket webSocket;
    private final Request requestToServer;
    private OnReceiveRow callback;
    public WebsocketConnection(String serverURI, OnReceiveRow callback) {
        OkHttpClient client = new OkHttpClient();
        requestToServer = new Request.Builder().url(serverURI).build();
        webSocket = client.newWebSocket(requestToServer, this);
        this.callback = callback;
    }
    
    @Override
    public void onOpen(WebSocket webSocket, Response response) {
        super.onOpen(webSocket, response);
        log("onOpen: " + response.message());
    }
    
    @Override
    public void onMessage(WebSocket webSocket, String text) {
        super.onMessage(webSocket, text);
        log("onMessage: " + text);
        
    }
    
    @Override
    public void onMessage(WebSocket webSocket, ByteString bytes) {
        super.onMessage(webSocket, bytes);
        log("onMessage: " + bytes.size() + "bytes received");
        callback.receiveRows(bytes);
    }
    
    @Override
    public void onClosing(WebSocket webSocket, int code, String reason) {
        super.onClosing(webSocket, code, reason);
        log("onClosing: " + reason + ", code:" + code);
    }
    
    @Override
    public void onClosed(WebSocket webSocket, int code, String reason) {
        super.onClosed(webSocket, code, reason);
        log("onClosed: " + reason + ", code:" + code);
    }
    
    @Override
    public void onFailure(WebSocket webSocket, Throwable t, Response response) {
        super.onFailure(webSocket, t, response);
        Log.e(DEBUG_TAG, "onFailure: " + t.getMessage());
        t.printStackTrace();
        
    }
    
    public void send(byte[] bytes){
        ByteString byteString = ByteString.of(bytes);
        webSocket.send(byteString);
    }
    
    public void close(){
        webSocket.close(1000, "fulfilled");
    }
    
    private void log(String s){
        Log.d(DEBUG_TAG, s);
    }
    
    interface OnReceiveRow{
        void receiveRows(ByteString bytes);
    }
}
\end{lstlisting}\vspace{14pt}

\clearpage
\liite{3}

\chapter{Node.js application listings}\label{appx:nodejsapp}
\addtocontents{toc}{\vspace{11pt}}

\begin{lstlisting}[label={listing:nodejsmain},caption={Main file},language=JavaScript, style=styleprogrammingappendix]
"use strict";

const express = require('express');
var WebsocketConnections = require('./websocketConnections');
var WebSocket = require('ws');
var url = require('url');
var http = require('http');
var params;

console.log("version 1.0");
var port = process.env.PORT || process.env.port || process.env.OPENSHIFT_NODEJS_PORT || 8080;
var ip = process.env.OPENSHIFT_NODEJS_IP || process.argv[2] || '0.0.0.0';

var PASSWORD = process.env.WS_PASSWORD;
var camDataPath = "/camera";
var clientDataPath = "/client";
var camConnections = new WebsocketConnections.CameraConnections();

/** http server: base */
const app = express();
app.get('/cams', function(req, res){
    res.send({ cams: camConnections.getInfo(), count: camConnections.count()});
});
const server = http.createServer(app);
main(server)

/** @function
*  @param {http.Server} server */
function main(server) {
    /** websocket server extends the http server */
    var wss = new WebSocket.Server({
        verifyClient: verifyClient,
        server: server
    });
    
    console.log("running on %s:%d", ip, port);
    
    wss.on('connection', function connection(ws) {
        var parsedUrl = url.parse(ws.upgradeReq.url);
        var path = parsedUrl.pathname;
        
        switch (path) {
            case camDataPath:  // a camera wants to register
            var camera_name = params.camera_name || undefined;
            var req = ws.upgradeReq;
            var ipAddress = req.headers['x-forwarded-for'] || 
            req.connection.remoteAddress || 
            req.socket.remoteAddress ||
            req.connection.socket.remoteAddress;
            camConnections.add(ws, camera_name, ipAddress);
            break;
            case clientDataPath:  // a client wants to register to a camera
            case "/":
            var camera_name = params.camera_name || "camera0";
            camConnections.addClientToCamera(camera_name, ws, function(err){
                if(err){ws.terminate();}
            });
            break;
            default:
            console.log("rejected: no valid path");
            ws.terminate();
            return;
        }
    });
    
    server.listen(port, ip);
}


function verifyClient(info) {
    var acceptHandshake = false;
    var accepted = "rejected: no valid password, use 'pass' parameter in the handshake please";
    var ip = info.req.connection.remoteAddress;
    var clientUrl = url.parse(info.req.url, true);
    params = clientUrl.query;
    
    acceptHandshake = params.pass == PASSWORD;
    
    if (acceptHandshake) {
        accepted = "accepted";
    }
    console.log("new client %s: %s", accepted, info.req.url);
    return acceptHandshake;
}
\end{lstlisting}

\begin{lstlisting}[label={listing:nodejsimplementation},caption={implementation of server-side classes},language=JavaScript, style=styleprogrammingappendix]
var WebSocket = require('ws');

/** A class that hold WebSocket clients for a camera
* @class
*/
function ClientConnections() {
    this.clients = [];
}
/** Lenght of the internal array of clients
* @method
*/
ClientConnections.prototype.getLength = function(){
    return this.clients.length;
};
/**@method
* @param {WebSocket} conn - client websocket connection to add
*/
ClientConnections.prototype.add = function (conn) {
    
    this.clients.push(conn);
    // console.log("client connections:%d", this.clients.length)
};
/**@method
* @param {WebSocket} conn - websocket connection to close
*/
ClientConnections.prototype.close = function (conn) {
    if(this.clients.length < 1){
        return;
    }
    var indx = this.clients.indexOf(conn);
    this.clients.splice(indx, 1);
};

/**send message to all websockets in the array
* @method
* @param {string} message 
*/
ClientConnections.prototype.sendToAll = function (message) {
    this.clients.forEach(function (client, ind, arr) {
        checkSocketOpen(client, function(){
            client.send(message);
        });
    });
};

/**Close all clients in the array
* @method
*/
ClientConnections.prototype.closeAll = function (message) {
    this.clients.forEach(function (client, ind, arr) {
        try{
            client.close();
        }catch(err){
            console.error(err.message);
        }
    });
};


/**A class that holds CameraClient objects
* @class
*/
function CameraConnections() {
    /** @member {Array} - this an array of clientcameras, no websockets connections */
    this.cameras = [];
}

/**
* @method
* @return {number} - number of cameras in the connected
*/
CameraConnections.prototype.count = function() {
    return this.cameras.length;
};


/**
* @method
* @return {array} - array of names of the cameras
*/
CameraConnections.prototype.getInfo = function() {
    var cams = [];
    this.cameras.forEach(function(element, index) {
        var name = element.name;
        if (element.name === undefined){
            name = "camera"+index;
        }
        var infoObject = {name:name, ip:element.ip};
        console.log(infoObject)
        cams.push(infoObject);
    }, this);
    return cams;    
};

/**
* @method
* @param {WebSocket} conn - connection to add
* @param {string} name - name of the socket
*/
CameraConnections.prototype.add = function (conn, name, ip) {
    var cname = name;
    var self = this;
    if (!cname) {
        cname = undefined; //name will be based on index
    }
    
    // defining the callbacks for this camera
    conn.on('message', incomingFromCamera);
    conn.on('close', closingCamera);
    
    var camera = new Camera(conn, cname, ip);
    this.cameras.push(camera);
    
    /** Callled when a connection to a camera is closed
    * @callback */
    function closingCamera(code, message) {
        try{
            camera.clients.closeAll();
            self.removeCamera(camera);
        }catch(err){
            console.error("Error on closing clients:"+err.message);
        }
        console.log("Camera %s closing connection: %d, %s", camera.name, code, message);
    }
    /** Called when data from a camera is comming
    * @callback */
    function incomingFromCamera(message, flags) {
        try {
            camera.clients.sendToAll(message);
        } catch (e) {
            console.error(e);
        }
    }
    return camera;
};
/**
* @method
* @param {(string|object|function)} cameraName - can be the name of the camera or a Camera object
* @param {WebSocket} clientConn
* @param {} callback
*/
CameraConnections.prototype.addClientToCamera = function (cameraName, clientConn, callback) {
    if(typeof cameraName === 'string'){
        this.getCamera(cameraName, tryAddClientToCamera);
    }else{
        tryAddClientToCamera(cameraName);
    }
    
    function tryAddClientToCamera(camera){
        if(!camera){
            var err = new Error("cannot add client to invalid camera: "+camera);
            callback(err);
            return;
        }
        
        // new client Callbacks
        clientConn.on('message', incomingFromClient);
        clientConn.on('close', closingClient);
        camera.clients.add(clientConn);
        callback();
        
        /** Called when a client sent data
        * @callback
        * @param {string} message 
        * @param {object} flags 
        */
        function incomingFromClient(message, flags) {
            camera.sendMessage(message);
        }
        /** Called when a connection to a client is closed
        * @callback
        * @param {number} code 
        * @param {string} message 
        */
        function closingClient(code) {
            camera.clients.close(clientConn);
            console.log("Closing client connection for: %s camera. info: %d, %s", camera.name, code);
        }
        
    }
};

CameraConnections.prototype.removeCamera = function(cameraClient){
    var indx = this.cameras.indexOf(cameraClient);
    this.cameras.splice(indx, 1);
};

CameraConnections.prototype.close = function(camera){
    // this will trigger closingCamera callback
    this.removeCamera(camera);
};
/**
* @method
* @param {string} name - name of the camera
* @param {} callback - callback which receives the camera object
*/
CameraConnections.prototype.getCamera = function (name, callback) {
    var cameraFound;
    this.cameras.forEach(function(c, index) {
        if (c.name == name || name == "camera"+index) {
            cameraFound = c;
        }
    }, this);
    
    callback(cameraFound);
};


/**@class
*  A camera client, it has a list of clients attached, and a unique name
*  @param {WebSocket} conn - connection object
*  @param {String} name - name of this camera (for identification)
*  @param {String} ip - ip address of this camera
*/
function Camera(conn, name, ip) {
    this.conn = conn;
    this.name = name;
    this.ip = ip;
    this.clients = new ClientConnections();
}

Camera.prototype.sendMessage = function (message) {
    var conn = this.conn;
    checkSocketOpen(conn, function(){
        conn.send(message);
    });
};

exports.ClientCamera = Camera;
exports.ClientConnections = ClientConnections;
exports.CameraConnections = CameraConnections;

/**
* 
* @param {WebSocket} socket 
* @param {} callback
*/
function checkSocketOpen(socket, callback){
    if(!socket){
        console.error('socket does not exists');
        return;
    }
    if(socket.readyState == WebSocket.OPEN){
        callback();
    }
}
\end{lstlisting}

\begin{lstlisting}[label={listing:robottest},caption={RobotFramework test file},language=Python, style=styleprogrammingappendix]
*** Variables ***
${password}                "password here"
${url}                     localhost:8080
${camera_name_param}       camera_name=
${url_params}              ?pass=${password}
${uri_client}              ws://${url}/client${url_params}&${camera_name_param}
${uri_camera}              ws://${url}/camera${url_params}&${camera_name_param}
${cloud_path}               ../
${cloud_app}                npm start --prefix  ${cloud_path}
${outf}                    log/stdout.txt
${errf}                    log/stderr.txt


*** Settings ***
Library           lib/WebsocketLibrary.py
Library           OperatingSystem
Library           Process
Library           HttpLibrary.HTTP
Suite Setup       Run Cloud
Suite Teardown    Close Cloud
Test Teardown     sleep  200 ms

*** Keywords ***
Close cloud
    Terminate All Processes
Run Cloud
    Remove Files                ${outf}  ${errf}
    Set Environment Variable    WS_PASSWORD  30022
    Start Process               ${cloud_app}   alias=cloud_process  stdout=${outf}  stderr=${errf}  shell=True
    sleep   1
    ${is_running} =             Is Process Running  handle=cloud_process
    Should Be True              ${is_running}   msg=Cloud is not running
Wait To Receive Message
    [arguments]   ${socket}  ${message}
    Wait Until Keyword Succeeds  5x  5 ms  Receive Next Message   ${socket}  ${message}
Wait Until Queue
    [arguments]   ${socket}   ${n}
    Wait Until Keyword Succeeds   5x  50 ms  Messages In Queue Should Be   ${socket}   ${n}
Create Camera Socket
    [arguments]   ${name}
    create socket  ${name}  ${uri_camera}${name}
    Create Camera Socket Noname
    create socket  noname  ${uri_camera}
Create Client Socket
    [arguments]   ${name}   ${camera_socket}
    create socket  ${name}  ${uri_client}${camera_socket}
Random Message
    ${randint}  Evaluate   str(random.randint(0, sys.maxint))   modules=random, sys
    [Return]   ${randint}
Send Random Message From
    [arguments]  ${socket}
    ${message}   Random Message
    Send From Socket  ${socket}  ${message}
Get Cameras
    Create Http Context 	${url}   http
    GET 	/cams
    Response Status Code Should Equal 	200
    ${body} = 	Get Response Body 	
    Should Start With 	${body} 	{
    Log Json  ${body}
Number Of Cameras Should Be
    [arguments]   ${n}
    Create Http Context 	${url}   http
    GET 	/cams
    Response Status Code Should Equal 	200
    ${body} = 	Get Response Body 	
    Json Value Should Equal  ${body}  /count  ${n}
    Log Json  ${body}
    
    
    *** Test Cases ***
    close sockets
    create Camera Socket         camera0
    Create Client Socket         client          camera0
    sleep                                100 ms
    Close Socket                 client
    Create Client Socket         client2          camera0
    sleep                                100 ms
    Close Socket                 client2
    
    
    Check Socket Library works
    Create Socket                client0  ${uri_camera}
    Do Exist Socket             client0
    
    Create camera client and send
    Create Camera Socket         camera0
    Create Client Socket         client0  camera0
    send From Socket             camera0  hi
    send From Socket             client0  hello
    
    cameras without name and with name
    create Camera Socket Noname
    create Camera Socket Noname
    create Camera Socket Noname
    create Camera Socket         1111special-cam1111
    create Camera Socket Noname
    create Camera Socket Noname
    sleep  80 ms
    Number Of Cameras Should Be    6
    
    
    5 cameras, 1 client, 5 messages
    create Camera Socket         camera0
    create Camera Socket         camera1
    create Camera Socket         camera-special
    create Camera Socket         camera3
    create Camera Socket         camera4
    Create Client Socket         client          camera-special
    sleep                                100 ms
    Get Cameras
    
    Send Random Message From             camera-special
    Send Random Message From             camera-special
    Send Random Message From             camera-special
    Send Random Message From             camera-special
    Send Random Message From             camera-special
    Wait Until Queue          client   5
    
    
    
    several cameras with several clients, bidirectional communication
    Create Camera Socket        cam
    Create Camera Socket        camf
    Create Client Socket        client       cam
    Create Client Socket        client1      cam
    Create Client Socket        client2      camf
    Create Client Socket        client3      camf
    sleep                                100 ms
    Get Cameras
    
    Send Random Message From             cam
    Send Random Message From             camf
    
    Wait Until Queue          client    1
    Wait Until Queue          client1   1
    Wait Until Queue          client2   1
    Wait Until Queue          client3   1
    
    Send Random Message From             client
    Send Random Message From             client1
    Send Random Message From             client2
    Send Random Message From             client3
    
    Wait Until Queue          cam       2
    Wait Until Queue          camf      2
    
    Http Server
    Get Cameras
\end{lstlisting}

\begin{lstlisting}[label={listing:robotlib},caption={RobotFramework websocket library},language=Python, style=styleprogrammingappendix]
#!/usr/bin/python
import subprocess
import sys
from Queue import Queue, Empty
from threading import Thread
import websocket
from robot.api import logger

__version__ = '0.1'
__author__ = "Alvaro Bolanos Rodriguez"


class WebsocketLibrary:
    ROBOT_LIBRARY_SCOPE = 'TEST CASE'
    ROBOT_LISTENER_API_VERSION = 2
    
    def __init__(self):
        self.ROBOT_LIBRARY_LISTENER = self
        # self.url = "%s:%d" % (host, port)
        self.socketDic = {}
    
    def _start_suite(self, name, attrs):
        print 'started suite'
    
    def _end_suite(self, name, attrs):
        print 'Suite %s (%s) ending.' % (name, attrs['id'])
    
    def _start_test(self, name, attrs):
        pass
        def _end_test(self, name, attrs):
        self.stop_all_sockets()
    
    def _get_socket(self, name):
        try:
            return self.socketDic.get(name)
        except Exception as e:
            logger.error(e.message)
    
    raise Exception("%s socket not found in list" % name)
    
    def create_socket(self, name, uri):
        ws = self.WebSocketConnection(uri, name=name)
        self.socketDic[name] = ws
        logger.info("created %s using %s" % (name, uri))
    
    def do_exist_socket(self, name):
        if self.socketDic.has_key(name):
            logger.info("'%s' exists" % name)
        else:
            raise AssertionError("'%s' does not exist" % name)
    
    def close_socket(self,name):
        s = self._get_socket(name)
        s.stop()
    
    def send_from_socket(self, socket, message):
        try:
            s = self._get_socket(socket)
            s.send_to_socket(message)
            logger.info("%s is sending '%s' message" % (s.name, message) )
        except websocket.WebSocketConnectionClosedException as e:
            logger.warn(e.message + ".Try using 'Wait to' keyword style")
    
    def stop_all_sockets(self):
        for name, socket in self.socketDic.items():
        socket.stop()
        self.socketDic = {}
    
    def receive_next_message(self, name, expected):
        ws = self._get_socket(name)
        try:
            received_message = ws.receive_next_message()
        except Empty as e:
            msg = e.message+"Message is not in Queue yet"
            logger.warn(msg)
            raise AssertionError(msg)
        if not ws:
            raise AssertionError("there is no websocket")
            if not received_message == expected:
                msg = "Messages do not match:'%s' is not '%s'" % (received_message, expected)
                logger.warn(msg)
                raise AssertionError(msg)
    
    def messages_in_queue_should_be(self, name, n):
        expected = int(n)
        s = self._get_socket(name)
        actual = s.in_queue.qsize()
        if actual != expected:
            raise AssertionError("number of elements does not match, was %d, expected %d" % (actual, expected))


class WebSocketConnection(Thread):
    def __init__(self, url, name):
        Thread.__init__(self, name=name)
        # websocket.enableTrace(True)
        self.url = url
        self.name = name
        self.in_queue = Queue(10)
        self.ws = websocket.WebSocketApp(self.url,
        on_message=self.on_message,
        on_error=self.on_error,
        on_close=self.on_close,
        on_open=self.on_open)
        self.setDaemon(True)
        self.start()
    
    def run(self):
        self.ws.run_forever()
    
    def on_message(self, ws, message):
        self.in_queue.put(message)
        logger.info("from %s:%s" % (self.name, message))
        
    def on_error(self, ws, error):
        logger.error(error)
    
    def on_close(self, ws):
        logger.info("closed %s" % self.name)
    
    def on_open(self, ws):
        logger.info("opened %s" % self.name)
    
    def stop(self):
        self.ws.close()
    
    def send_to_socket(self, data):
        self.ws.send(data)
    
    def receive_next_message(self):
        return self.in_queue.get(block=False)

\end{lstlisting}


%\clearpage
%\liite{5}
\end{document}
